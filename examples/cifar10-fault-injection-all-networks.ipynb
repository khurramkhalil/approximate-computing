{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98a115dd",
   "metadata": {},
   "source": [
    "# Model evaluation and re-training with AdaPT on Cifar10 dataset\n",
    "\n",
    "In this notebook you can evaluate different approximate multipliers on various models based on Cifar10 dataset\n",
    "\n",
    "Steps:\n",
    "* Select models to load \n",
    "* Select number of threads to use\n",
    "* Choose approximate multiplier \n",
    "* Load model for evaluation\n",
    "* Load dataset\n",
    "* Run model calibration for quantization\n",
    "* Run model evaluation\n",
    "* Run approximate-aware re-training\n",
    "* Rerun model evaluation\n",
    "\n",
    "**Note**:\n",
    "* This notebook should be run on a X86 machine\n",
    "\n",
    "* Please make sure you have run the installation steps first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5eef0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "import requests\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms as T\n",
    "from torchvision.datasets import CIFAR10, CIFAR100\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5d4c7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_seed():\n",
    "    return 1221 # 121 and 1221\n",
    "\n",
    "def set_random_seeds():\n",
    "    torch.manual_seed(get_random_seed())\n",
    "    np.random.seed(get_random_seed())\n",
    "    random.seed(get_random_seed())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab49b35",
   "metadata": {},
   "source": [
    "## Select models to load \n",
    "\n",
    "The weights must be downloaded in state_dicts folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "183a13aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.SDNs.vgg_sdn import vgg16_sdn_bn\n",
    "from models.SDNs.wideresnet_sdn import wideresnet_sdn_v1\n",
    "from models.SDNs.mobilenet_sdn import mobilenet_sdn_v1\n",
    "import models.SDNs.fault_injection as fie\n",
    "import models.SDNs.sdm_fault_mitigation as sdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69265983",
   "metadata": {},
   "source": [
    "## Select number of threads to use\n",
    "\n",
    "For optimal performance set them as the number of your cpu threads (not cpu cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "165c2d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: OMP_PLACES=cores\n",
      "env: OMP_PROC_BIND=close\n",
      "env: OMP_WAIT_POLICY=active\n"
     ]
    }
   ],
   "source": [
    "threads = 20\n",
    "torch.set_num_threads(threads)\n",
    "\n",
    "# maybe better performance\n",
    "%env OMP_PLACES=cores\n",
    "%env OMP_PROC_BIND=close\n",
    "%env OMP_WAIT_POLICY=active"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa06300",
   "metadata": {},
   "source": [
    "## Choose approximate multiplier \n",
    "\n",
    "Two approximate multipliers are already provided\n",
    "\n",
    "**mul8s_acc** - (header file: mul8s_acc.h)   <--  default\n",
    "\n",
    "**mul8s_1L2H** - (header file: mul8s_1L2H.h)\n",
    "\n",
    "\n",
    "\n",
    "In order to use your custom multiplier you need to use the provided tool (LUT_generator) to easily create the C++ header for your multiplier. Then you just place it inside the adapt/cpu-kernels/axx_mults folder. The name of the axx_mult here must match the name of the header file. The same axx_mult is used in all layers. \n",
    "\n",
    "Tip: If you want explicitly to set for each layer a different axx_mult you must do it from the model definition using the respective AdaPT_Conv2d class of each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "562689c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# axx_mult = 'mul8s_acc'\n",
    "axx_mult = 'mul8s_1KV6'\n",
    "# axx_mult = 'mul8s_1KV8'\n",
    "# axx_mult = 'mul8s_1KV9'\n",
    "# axx_mult = 'mul8s_1KVP'\n",
    "# axx_mult = 'mul8s_1L2J'\n",
    "# axx_mult = 'mul8s_1L2H'\n",
    "# axx_mult = 'mul8s_1L2N'\n",
    "# axx_mult = 'mul8s_1L12'\n",
    "\n",
    "dataset_name = \"CIFAR100\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b539e7e1",
   "metadata": {},
   "source": [
    "## Load model for evaluation\n",
    "\n",
    "Jit compilation method loads 'on the fly' the C++ extentions of the approximate multipliers. Then the pytorch model is loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc26796f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Emitting ninja build file /root/.cache/torch_extensions/PyInit_conv2d_mul8s_1KV6/build.ninja...\n",
      "Building extension module PyInit_conv2d_mul8s_1KV6...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module PyInit_conv2d_mul8s_1KV6...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1KV6, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1KV6...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1KV6, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1KV6...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1KV6, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1KV6...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1KV6, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1KV6...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1KV6, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1KV6...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1KV6, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1KV6...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1KV6, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1KV6...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1KV6, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1KV6...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1KV6, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1KV6...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1KV6, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1KV6...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1KV6, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1KV6...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1KV6, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1KV6...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1KV6, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1KV6...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1KV6, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1KV6...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1KV6, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1KV6...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1KV6, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1KV6...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1KV6, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1KV6...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1KV6, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1KV6...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1KV6, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1KV6...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1KV6, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1KV6...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1KV6, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1KV6...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1KV6, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1KV6...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1KV6, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1KV6...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1KV6, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1KV6...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1KV6, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1KV6...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1KV6, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1KV6...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MobileNet_SDN(\n",
       "  (init_conv): Sequential(\n",
       "    (0): AdaPT_Conv2d(\n",
       "      3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
       "      (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "      (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "    )\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "  )\n",
       "  (layers): ModuleList(\n",
       "    (0): BlockWOutput(\n",
       "      (layers): Sequential(\n",
       "        (0): AdaPT_Conv2d(\n",
       "          32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
       "          (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "          (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        )\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): AdaPT_Conv2d(\n",
       "          32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "          (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        )\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU()\n",
       "      )\n",
       "      (output): Sequential()\n",
       "    )\n",
       "    (1): BlockWOutput(\n",
       "      (layers): Sequential(\n",
       "        (0): AdaPT_Conv2d(\n",
       "          64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False\n",
       "          (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "          (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        )\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): AdaPT_Conv2d(\n",
       "          64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "          (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        )\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU()\n",
       "      )\n",
       "      (output): Sequential()\n",
       "    )\n",
       "    (2): BlockWOutput(\n",
       "      (layers): Sequential(\n",
       "        (0): AdaPT_Conv2d(\n",
       "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False\n",
       "          (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "          (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        )\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): AdaPT_Conv2d(\n",
       "          128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "          (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        )\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU()\n",
       "      )\n",
       "      (output): InternalClassifier(\n",
       "        (max_pool): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "        (avg_pool): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
       "        (linear): Linear(in_features=2048, out_features=100, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (3): BlockWOutput(\n",
       "      (layers): Sequential(\n",
       "        (0): AdaPT_Conv2d(\n",
       "          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False\n",
       "          (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "          (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        )\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): AdaPT_Conv2d(\n",
       "          128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "          (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        )\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU()\n",
       "      )\n",
       "      (output): Sequential()\n",
       "    )\n",
       "    (4): BlockWOutput(\n",
       "      (layers): Sequential(\n",
       "        (0): AdaPT_Conv2d(\n",
       "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False\n",
       "          (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "          (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        )\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): AdaPT_Conv2d(\n",
       "          256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "          (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        )\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU()\n",
       "      )\n",
       "      (output): InternalClassifier(\n",
       "        (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (avg_pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        (linear): Linear(in_features=4096, out_features=100, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (5): BlockWOutput(\n",
       "      (layers): Sequential(\n",
       "        (0): AdaPT_Conv2d(\n",
       "          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False\n",
       "          (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "          (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        )\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): AdaPT_Conv2d(\n",
       "          256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "          (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        )\n",
       "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU()\n",
       "      )\n",
       "      (output): Sequential()\n",
       "    )\n",
       "    (6): BlockWOutput(\n",
       "      (layers): Sequential(\n",
       "        (0): AdaPT_Conv2d(\n",
       "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False\n",
       "          (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "          (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        )\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): AdaPT_Conv2d(\n",
       "          512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "          (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        )\n",
       "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU()\n",
       "      )\n",
       "      (output): InternalClassifier(\n",
       "        (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "        (avg_pool): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
       "        (linear): Linear(in_features=8192, out_features=100, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (7): BlockWOutput(\n",
       "      (layers): Sequential(\n",
       "        (0): AdaPT_Conv2d(\n",
       "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False\n",
       "          (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "          (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        )\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): AdaPT_Conv2d(\n",
       "          512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "          (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        )\n",
       "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU()\n",
       "      )\n",
       "      (output): Sequential()\n",
       "    )\n",
       "    (8): BlockWOutput(\n",
       "      (layers): Sequential(\n",
       "        (0): AdaPT_Conv2d(\n",
       "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False\n",
       "          (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "          (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        )\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): AdaPT_Conv2d(\n",
       "          512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "          (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        )\n",
       "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU()\n",
       "      )\n",
       "      (output): InternalClassifier(\n",
       "        (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "        (avg_pool): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
       "        (linear): Linear(in_features=8192, out_features=100, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (9): BlockWOutput(\n",
       "      (layers): Sequential(\n",
       "        (0): AdaPT_Conv2d(\n",
       "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False\n",
       "          (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "          (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        )\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): AdaPT_Conv2d(\n",
       "          512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "          (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        )\n",
       "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU()\n",
       "      )\n",
       "      (output): Sequential()\n",
       "    )\n",
       "    (10): BlockWOutput(\n",
       "      (layers): Sequential(\n",
       "        (0): AdaPT_Conv2d(\n",
       "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False\n",
       "          (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "          (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        )\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): AdaPT_Conv2d(\n",
       "          512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "          (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        )\n",
       "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU()\n",
       "      )\n",
       "      (output): Sequential()\n",
       "    )\n",
       "    (11): BlockWOutput(\n",
       "      (layers): Sequential(\n",
       "        (0): AdaPT_Conv2d(\n",
       "          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False\n",
       "          (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "          (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        )\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): AdaPT_Conv2d(\n",
       "          512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "          (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        )\n",
       "        (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU()\n",
       "      )\n",
       "      (output): InternalClassifier(\n",
       "        (linear): Linear(in_features=4096, out_features=100, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (12): BlockWOutput(\n",
       "      (layers): Sequential(\n",
       "        (0): AdaPT_Conv2d(\n",
       "          1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False\n",
       "          (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "          (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        )\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): AdaPT_Conv2d(\n",
       "          1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "          (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "          (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        )\n",
       "        (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU()\n",
       "      )\n",
       "      (output): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (end_layers): Sequential(\n",
       "    (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    (1): Flatten(start_dim=1, end_dim=-1)\n",
       "    (2): Linear(in_features=1024, out_features=100, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = vgg16_sdn_bn(pretrained=True, axx_mult = axx_mult, dataset_name=dataset_name)\n",
    "# model = wideresnet_sdn_v1(pretrained=True, axx_mult = axx_mult, dataset_name=dataset_name)\n",
    "model = mobilenet_sdn_v1(pretrained=True, axx_mult = axx_mult, dataset_name=dataset_name)\n",
    "\n",
    "model.eval() # for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7de58a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "init_conv\n",
      "init_conv.0\n",
      "init_conv.0.quantizer\n",
      "init_conv.0.quantizer_w\n",
      "init_conv.1\n",
      "init_conv.2\n",
      "layers\n",
      "layers.0\n",
      "layers.0.layers\n",
      "layers.0.layers.0\n",
      "layers.0.layers.0.quantizer\n",
      "layers.0.layers.0.quantizer_w\n",
      "layers.0.layers.1\n",
      "layers.0.layers.2\n",
      "layers.0.layers.3\n",
      "layers.0.layers.3.quantizer\n",
      "layers.0.layers.3.quantizer_w\n",
      "layers.0.layers.4\n",
      "layers.0.layers.5\n",
      "layers.0.output\n",
      "layers.1\n",
      "layers.1.layers\n",
      "layers.1.layers.0\n",
      "layers.1.layers.0.quantizer\n",
      "layers.1.layers.0.quantizer_w\n",
      "layers.1.layers.1\n",
      "layers.1.layers.2\n",
      "layers.1.layers.3\n",
      "layers.1.layers.3.quantizer\n",
      "layers.1.layers.3.quantizer_w\n",
      "layers.1.layers.4\n",
      "layers.1.layers.5\n",
      "layers.1.output\n",
      "layers.2\n",
      "layers.2.layers\n",
      "layers.2.layers.0\n",
      "layers.2.layers.0.quantizer\n",
      "layers.2.layers.0.quantizer_w\n",
      "layers.2.layers.1\n",
      "layers.2.layers.2\n",
      "layers.2.layers.3\n",
      "layers.2.layers.3.quantizer\n",
      "layers.2.layers.3.quantizer_w\n",
      "layers.2.layers.4\n",
      "layers.2.layers.5\n",
      "layers.2.output\n",
      "layers.2.output.max_pool\n",
      "layers.2.output.avg_pool\n",
      "layers.2.output.linear\n",
      "layers.3\n",
      "layers.3.layers\n",
      "layers.3.layers.0\n",
      "layers.3.layers.0.quantizer\n",
      "layers.3.layers.0.quantizer_w\n",
      "layers.3.layers.1\n",
      "layers.3.layers.2\n",
      "layers.3.layers.3\n",
      "layers.3.layers.3.quantizer\n",
      "layers.3.layers.3.quantizer_w\n",
      "layers.3.layers.4\n",
      "layers.3.layers.5\n",
      "layers.3.output\n",
      "layers.4\n",
      "layers.4.layers\n",
      "layers.4.layers.0\n",
      "layers.4.layers.0.quantizer\n",
      "layers.4.layers.0.quantizer_w\n",
      "layers.4.layers.1\n",
      "layers.4.layers.2\n",
      "layers.4.layers.3\n",
      "layers.4.layers.3.quantizer\n",
      "layers.4.layers.3.quantizer_w\n",
      "layers.4.layers.4\n",
      "layers.4.layers.5\n",
      "layers.4.output\n",
      "layers.4.output.max_pool\n",
      "layers.4.output.avg_pool\n",
      "layers.4.output.linear\n",
      "layers.5\n",
      "layers.5.layers\n",
      "layers.5.layers.0\n",
      "layers.5.layers.0.quantizer\n",
      "layers.5.layers.0.quantizer_w\n",
      "layers.5.layers.1\n",
      "layers.5.layers.2\n",
      "layers.5.layers.3\n",
      "layers.5.layers.3.quantizer\n",
      "layers.5.layers.3.quantizer_w\n",
      "layers.5.layers.4\n",
      "layers.5.layers.5\n",
      "layers.5.output\n",
      "layers.6\n",
      "layers.6.layers\n",
      "layers.6.layers.0\n",
      "layers.6.layers.0.quantizer\n",
      "layers.6.layers.0.quantizer_w\n",
      "layers.6.layers.1\n",
      "layers.6.layers.2\n",
      "layers.6.layers.3\n",
      "layers.6.layers.3.quantizer\n",
      "layers.6.layers.3.quantizer_w\n",
      "layers.6.layers.4\n",
      "layers.6.layers.5\n",
      "layers.6.output\n",
      "layers.6.output.max_pool\n",
      "layers.6.output.avg_pool\n",
      "layers.6.output.linear\n",
      "layers.7\n",
      "layers.7.layers\n",
      "layers.7.layers.0\n",
      "layers.7.layers.0.quantizer\n",
      "layers.7.layers.0.quantizer_w\n",
      "layers.7.layers.1\n",
      "layers.7.layers.2\n",
      "layers.7.layers.3\n",
      "layers.7.layers.3.quantizer\n",
      "layers.7.layers.3.quantizer_w\n",
      "layers.7.layers.4\n",
      "layers.7.layers.5\n",
      "layers.7.output\n",
      "layers.8\n",
      "layers.8.layers\n",
      "layers.8.layers.0\n",
      "layers.8.layers.0.quantizer\n",
      "layers.8.layers.0.quantizer_w\n",
      "layers.8.layers.1\n",
      "layers.8.layers.2\n",
      "layers.8.layers.3\n",
      "layers.8.layers.3.quantizer\n",
      "layers.8.layers.3.quantizer_w\n",
      "layers.8.layers.4\n",
      "layers.8.layers.5\n",
      "layers.8.output\n",
      "layers.8.output.max_pool\n",
      "layers.8.output.avg_pool\n",
      "layers.8.output.linear\n",
      "layers.9\n",
      "layers.9.layers\n",
      "layers.9.layers.0\n",
      "layers.9.layers.0.quantizer\n",
      "layers.9.layers.0.quantizer_w\n",
      "layers.9.layers.1\n",
      "layers.9.layers.2\n",
      "layers.9.layers.3\n",
      "layers.9.layers.3.quantizer\n",
      "layers.9.layers.3.quantizer_w\n",
      "layers.9.layers.4\n",
      "layers.9.layers.5\n",
      "layers.9.output\n",
      "layers.10\n",
      "layers.10.layers\n",
      "layers.10.layers.0\n",
      "layers.10.layers.0.quantizer\n",
      "layers.10.layers.0.quantizer_w\n",
      "layers.10.layers.1\n",
      "layers.10.layers.2\n",
      "layers.10.layers.3\n",
      "layers.10.layers.3.quantizer\n",
      "layers.10.layers.3.quantizer_w\n",
      "layers.10.layers.4\n",
      "layers.10.layers.5\n",
      "layers.10.output\n",
      "layers.11\n",
      "layers.11.layers\n",
      "layers.11.layers.0\n",
      "layers.11.layers.0.quantizer\n",
      "layers.11.layers.0.quantizer_w\n",
      "layers.11.layers.1\n",
      "layers.11.layers.2\n",
      "layers.11.layers.3\n",
      "layers.11.layers.3.quantizer\n",
      "layers.11.layers.3.quantizer_w\n",
      "layers.11.layers.4\n",
      "layers.11.layers.5\n",
      "layers.11.output\n",
      "layers.11.output.linear\n",
      "layers.12\n",
      "layers.12.layers\n",
      "layers.12.layers.0\n",
      "layers.12.layers.0.quantizer\n",
      "layers.12.layers.0.quantizer_w\n",
      "layers.12.layers.1\n",
      "layers.12.layers.2\n",
      "layers.12.layers.3\n",
      "layers.12.layers.3.quantizer\n",
      "layers.12.layers.3.quantizer_w\n",
      "layers.12.layers.4\n",
      "layers.12.layers.5\n",
      "layers.12.output\n",
      "end_layers\n",
      "end_layers.0\n",
      "end_layers.1\n",
      "end_layers.2\n"
     ]
    }
   ],
   "source": [
    "# Set random seeds\n",
    "set_random_seeds()\n",
    "\n",
    "# Print names of immediate layers only\n",
    "for name, layer in model.named_modules():\n",
    "    print(name)\n",
    "    \n",
    "# layers.0.layers.0.quantizer\n",
    "# layers.0.layers.0.quantizer_w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2fc2735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set random seeds\n",
    "# set_random_seeds()\n",
    "# from scipy import stats\n",
    "# from adapt.approx_layers import axx_layers as approxNN\n",
    "\n",
    "# check_layer = \"init_conv.weight\"\n",
    "# initial_stats = {}\n",
    "# # Print names of immediate layers only\n",
    "# for name, module in model.named_modules():\n",
    "#     print(name)\n",
    "#     if isinstance(module, approxNN.AdaPT_Conv2d) and name in check_layer:\n",
    "#         print(\"This\")\n",
    "#         weights = module.weight.data.cpu().numpy().flatten()\n",
    "#         initial_stats[name] = {\n",
    "#             'mean': np.mean(weights),\n",
    "#             'std': np.std(weights),\n",
    "#             'sample': np.random.choice(weights, size=100, replace=False)\n",
    "#         }\n",
    "#         print(\"length: \", len(weights))\n",
    "#         break\n",
    "\n",
    "\n",
    "# module = dict(model.named_modules())[name]\n",
    "# current_weights = module.weight.data.cpu().numpy().flatten()\n",
    "# current_sample = np.random.choice(current_weights, size=100, replace=False)\n",
    "\n",
    "# ks_statistic, p_value = stats.ks_2samp(initial_stats[name]['sample'], current_sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76721ed0",
   "metadata": {},
   "source": [
    "## Load dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f63b4701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "def val_dataloader(mean = (0.4914, 0.4822, 0.4465), std = (0.2471, 0.2435, 0.2616)):\n",
    "\n",
    "    transform = T.Compose(\n",
    "        [\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean, std),\n",
    "        ]\n",
    "    )\n",
    "    dataset = CIFAR10(root=\"datasets/cifar10_data\", train=False, download=True, transform=transform)\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=128,\n",
    "        num_workers=0,\n",
    "        drop_last=True,\n",
    "        pin_memory=False,\n",
    "    )\n",
    "    return dataloader\n",
    "\n",
    "transform = T.Compose(\n",
    "        [\n",
    "            T.RandomCrop(32, padding=4),\n",
    "            T.RandomHorizontalFlip(),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225)),\n",
    "        ]\n",
    "    )\n",
    "dataset = CIFAR10(root=\"datasets/cifar10_data\", train=True, download=True, transform=transform)\n",
    "\n",
    "evens = list(range(0, len(dataset), 10))\n",
    "trainset_1 = torch.utils.data.Subset(dataset, evens)\n",
    "\n",
    "data = val_dataloader()\n",
    "\n",
    "# data_t is used for calibration purposes and is a subset of train-set\n",
    "data_t = DataLoader(trainset_1, batch_size=128,\n",
    "                                            shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47aa7856",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cifar10_:\n",
    "    def __init__(self, batch_size=128, add_trigger=False):\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = 32\n",
    "        self.num_classes = 10\n",
    "        self.num_test = 100  # Set the number of test samples to 2000\n",
    "        self.num_train = 50000\n",
    "\n",
    "        normalize = T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        self.augmented = T.Compose([T.RandomHorizontalFlip(), T.RandomCrop(32, padding=4), T.ToTensor(), normalize])\n",
    "        self.normalized = T.Compose([T.ToTensor(), normalize])\n",
    "\n",
    "        self.aug_trainset = CIFAR10(root='datasets/cifar10_data', train=True, download=False, transform=self.augmented)\n",
    "        self.aug_train_loader = torch.utils.data.DataLoader(self.aug_trainset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "        self.trainset = CIFAR10(root='datasets/cifar10_data', train=True, download=False, transform=self.normalized)\n",
    "        self.train_loader = torch.utils.data.DataLoader(self.trainset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        # Load the full test set\n",
    "        self.full_testset = CIFAR10(root='datasets/cifar10_data', train=False, download=False, transform=self.normalized)\n",
    "        \n",
    "        indices = np.random.choice(len(self.full_testset), self.num_test, replace=False)\n",
    "        \n",
    "        # Create a subset of the test set with these indices\n",
    "        self.testset = torch.utils.data.Subset(self.full_testset, indices)\n",
    "        self.test_loader = torch.utils.data.DataLoader(self.testset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "class Cifar100_:\n",
    "    def __init__(self, batch_size=128, add_trigger=False):\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = 32\n",
    "        self.num_classes = 10\n",
    "        self.num_test = 100  # Set the number of test samples to 2000\n",
    "        self.num_train = 50000\n",
    "\n",
    "        normalize = T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        self.augmented = T.Compose([T.RandomHorizontalFlip(), T.RandomCrop(32, padding=4), T.ToTensor(), normalize])\n",
    "        self.normalized = T.Compose([T.ToTensor(), normalize])\n",
    "\n",
    "        self.aug_trainset = CIFAR100(root='datasets/cifar100_data', train=True, download=False, transform=self.augmented)\n",
    "        self.aug_train_loader = torch.utils.data.DataLoader(self.aug_trainset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "        self.trainset = CIFAR100(root='datasets/cifar100_data', train=True, download=False, transform=self.normalized)\n",
    "        self.train_loader = torch.utils.data.DataLoader(self.trainset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        # Load the full test set\n",
    "        self.full_testset = CIFAR100(root='datasets/cifar100_data', train=False, download=False, transform=self.normalized)\n",
    "        \n",
    "        indices = np.random.choice(len(self.full_testset), self.num_test, replace=False)\n",
    "        \n",
    "        # Create a subset of the test set with these indices\n",
    "        self.testset = torch.utils.data.Subset(self.full_testset, indices)\n",
    "        self.test_loader = torch.utils.data.DataLoader(self.testset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "        \n",
    "def load_dataset(batch_size, add_trigger=False):\n",
    "    cifar10_data = Cifar10_(batch_size=batch_size, add_trigger=add_trigger) if dataset_name==\"CIFAR10\" else  \\\n",
    "                                    Cifar100_(batch_size=batch_size, add_trigger=add_trigger)\n",
    "    return cifar10_data\n",
    "\n",
    "def get_dataset(batch_size=128, add_trigger=False):\n",
    "    return load_dataset(batch_size, add_trigger)\n",
    "\n",
    "t_dataset = get_dataset()\n",
    "one_batch_dataset = get_dataset(1, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa74c5d",
   "metadata": {},
   "source": [
    "## Run model calibration for quantization\n",
    "\n",
    "Calibrates the quantization parameters \n",
    "\n",
    "Need to re-run it each time the model changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "946f0d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:05<00:00,  2.88s/it]\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0917 17:04:43.294075 140008678897472 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0917 17:04:43.294453 140008678897472 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0917 17:04:43.294768 140008678897472 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0917 17:04:43.295048 140008678897472 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0917 17:04:43.295328 140008678897472 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0917 17:04:43.295602 140008678897472 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0917 17:04:43.296369 140008678897472 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0917 17:04:43.296849 140008678897472 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0917 17:04:43.297226 140008678897472 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0917 17:04:43.298451 140008678897472 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0917 17:04:43.298967 140008678897472 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0917 17:04:43.299245 140008678897472 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0917 17:04:43.299526 140008678897472 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0917 17:04:43.300470 140008678897472 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0917 17:04:43.300762 140008678897472 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0917 17:04:43.301041 140008678897472 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0917 17:04:43.301325 140008678897472 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0917 17:04:43.301611 140008678897472 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0917 17:04:43.301941 140008678897472 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0917 17:04:43.304101 140008678897472 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0917 17:04:43.304550 140008678897472 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0917 17:04:43.304904 140008678897472 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0917 17:04:43.305177 140008678897472 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0917 17:04:43.305423 140008678897472 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0917 17:04:43.305670 140008678897472 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0917 17:04:43.305905 140008678897472 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0917 17:04:43.306148 140008678897472 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0917 17:04:43.306384 140008678897472 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0917 17:04:43.306619 140008678897472 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0917 17:04:43.306848 140008678897472 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0917 17:04:43.307100 140008678897472 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0917 17:04:43.307324 140008678897472 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0917 17:04:43.307559 140008678897472 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0917 17:04:43.307809 140008678897472 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0917 17:04:43.308054 140008678897472 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0917 17:04:43.308281 140008678897472 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0917 17:04:43.308530 140008678897472 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0917 17:04:43.308765 140008678897472 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0917 17:04:43.309021 140008678897472 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0917 17:04:43.309259 140008678897472 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0917 17:04:43.309494 140008678897472 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0917 17:04:43.309716 140008678897472 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0917 17:04:43.309948 140008678897472 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0917 17:04:43.310175 140008678897472 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0917 17:04:43.310400 140008678897472 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0917 17:04:43.310619 140008678897472 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0917 17:04:43.310851 140008678897472 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0917 17:04:43.311074 140008678897472 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0917 17:04:43.311300 140008678897472 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0917 17:04:43.311522 140008678897472 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0917 17:04:43.311758 140008678897472 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0917 17:04:43.311976 140008678897472 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0917 17:04:43.312201 140008678897472 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0917 17:04:43.312422 140008678897472 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0917 17:04:43.312800 140008678897472 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0917 17:04:43.314826 140008678897472 tensor_quantizer.py:238] Call .cuda() if running on GPU after loading calibrated amax.\n",
      "W0917 17:04:43.315352 140008678897472 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0917 17:04:43.315875 140008678897472 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0917 17:04:43.316346 140008678897472 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0917 17:04:43.316817 140008678897472 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0917 17:04:43.317276 140008678897472 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0917 17:04:43.317737 140008678897472 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0917 17:04:43.318076 140008678897472 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0917 17:04:43.318634 140008678897472 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0917 17:04:43.319098 140008678897472 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0917 17:04:43.319571 140008678897472 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0917 17:04:43.320034 140008678897472 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0917 17:04:43.320502 140008678897472 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0917 17:04:43.320831 140008678897472 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0917 17:04:43.321246 140008678897472 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0917 17:04:43.321893 140008678897472 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0917 17:04:43.322222 140008678897472 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0917 17:04:43.322844 140008678897472 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0917 17:04:43.323356 140008678897472 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0917 17:04:43.323689 140008678897472 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0917 17:04:43.324223 140008678897472 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0917 17:04:43.324559 140008678897472 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0917 17:04:43.325112 140008678897472 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0917 17:04:43.325568 140008678897472 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0917 17:04:43.325899 140008678897472 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0917 17:04:43.326425 140008678897472 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0917 17:04:43.326757 140008678897472 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0917 17:04:43.327293 140008678897472 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0917 17:04:43.327739 140008678897472 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0917 17:04:43.328177 140008678897472 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0917 17:04:43.328663 140008678897472 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0917 17:04:43.329109 140008678897472 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0917 17:04:43.329452 140008678897472 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0917 17:04:43.329984 140008678897472 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0917 17:04:43.330321 140008678897472 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0917 17:04:43.330851 140008678897472 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0917 17:04:43.331183 140008678897472 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0917 17:04:43.331707 140008678897472 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0917 17:04:43.332051 140008678897472 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0917 17:04:43.332576 140008678897472 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0917 17:04:43.332904 140008678897472 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0917 17:04:43.333429 140008678897472 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0917 17:04:43.333871 140008678897472 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0917 17:04:43.334301 140008678897472 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0917 17:04:43.334622 140008678897472 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0917 17:04:43.335142 140008678897472 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0917 17:04:43.335469 140008678897472 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0917 17:04:43.335998 140008678897472 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0917 17:04:43.336329 140008678897472 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0917 17:04:43.336854 140008678897472 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0917 17:04:43.337352 140008678897472 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0917 17:04:43.337840 140008678897472 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0917 17:04:43.338197 140008678897472 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0917 17:04:43.338526 140008678897472 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init_conv.0.quantizer                   : TensorQuantizer(8bit per-tensor amax=2.6387 calibrator=HistogramCalibrator quant)\n",
      "init_conv.0.quantizer_w                 : TensorQuantizer(8bit per-tensor amax=2.7927 calibrator=HistogramCalibrator quant)\n",
      "layers.0.layers.0.quantizer             : TensorQuantizer(8bit per-tensor amax=6.6096 calibrator=HistogramCalibrator quant)\n",
      "layers.0.layers.0.quantizer_w           : TensorQuantizer(8bit per-tensor amax=2.6496 calibrator=HistogramCalibrator quant)\n",
      "layers.0.layers.3.quantizer             : TensorQuantizer(8bit per-tensor amax=8.9233 calibrator=HistogramCalibrator quant)\n",
      "layers.0.layers.3.quantizer_w           : TensorQuantizer(8bit per-tensor amax=1.9375 calibrator=HistogramCalibrator quant)\n",
      "layers.1.layers.0.quantizer             : TensorQuantizer(8bit per-tensor amax=4.9031 calibrator=HistogramCalibrator quant)\n",
      "layers.1.layers.0.quantizer_w           : TensorQuantizer(8bit per-tensor amax=1.5331 calibrator=HistogramCalibrator quant)\n",
      "layers.1.layers.3.quantizer             : TensorQuantizer(8bit per-tensor amax=6.7759 calibrator=HistogramCalibrator quant)\n",
      "layers.1.layers.3.quantizer_w           : TensorQuantizer(8bit per-tensor amax=1.3719 calibrator=HistogramCalibrator quant)\n",
      "layers.2.layers.0.quantizer             : TensorQuantizer(8bit per-tensor amax=3.3496 calibrator=HistogramCalibrator quant)\n",
      "layers.2.layers.0.quantizer_w           : TensorQuantizer(8bit per-tensor amax=1.4025 calibrator=HistogramCalibrator quant)\n",
      "layers.2.layers.3.quantizer             : TensorQuantizer(8bit per-tensor amax=6.2079 calibrator=HistogramCalibrator quant)\n",
      "layers.2.layers.3.quantizer_w           : TensorQuantizer(8bit per-tensor amax=1.1976 calibrator=HistogramCalibrator quant)\n",
      "layers.3.layers.0.quantizer             : TensorQuantizer(8bit per-tensor amax=3.3918 calibrator=HistogramCalibrator quant)\n",
      "layers.3.layers.0.quantizer_w           : TensorQuantizer(8bit per-tensor amax=0.7158 calibrator=HistogramCalibrator quant)\n",
      "layers.3.layers.3.quantizer             : TensorQuantizer(8bit per-tensor amax=6.6268 calibrator=HistogramCalibrator quant)\n",
      "layers.3.layers.3.quantizer_w           : TensorQuantizer(8bit per-tensor amax=0.8243 calibrator=HistogramCalibrator quant)\n",
      "layers.4.layers.0.quantizer             : TensorQuantizer(8bit per-tensor amax=2.3900 calibrator=HistogramCalibrator quant)\n",
      "layers.4.layers.0.quantizer_w           : TensorQuantizer(8bit per-tensor amax=1.0772 calibrator=HistogramCalibrator quant)\n",
      "layers.4.layers.3.quantizer             : TensorQuantizer(8bit per-tensor amax=3.6696 calibrator=HistogramCalibrator quant)\n",
      "layers.4.layers.3.quantizer_w           : TensorQuantizer(8bit per-tensor amax=0.6458 calibrator=HistogramCalibrator quant)\n",
      "layers.5.layers.0.quantizer             : TensorQuantizer(8bit per-tensor amax=1.9484 calibrator=HistogramCalibrator quant)\n",
      "layers.5.layers.0.quantizer_w           : TensorQuantizer(8bit per-tensor amax=0.5505 calibrator=HistogramCalibrator quant)\n",
      "layers.5.layers.3.quantizer             : TensorQuantizer(8bit per-tensor amax=4.1994 calibrator=HistogramCalibrator quant)\n",
      "layers.5.layers.3.quantizer_w           : TensorQuantizer(8bit per-tensor amax=0.4649 calibrator=HistogramCalibrator quant)\n",
      "layers.6.layers.0.quantizer             : TensorQuantizer(8bit per-tensor amax=1.7219 calibrator=HistogramCalibrator quant)\n",
      "layers.6.layers.0.quantizer_w           : TensorQuantizer(8bit per-tensor amax=0.7162 calibrator=HistogramCalibrator quant)\n",
      "layers.6.layers.3.quantizer             : TensorQuantizer(8bit per-tensor amax=2.9989 calibrator=HistogramCalibrator quant)\n",
      "layers.6.layers.3.quantizer_w           : TensorQuantizer(8bit per-tensor amax=0.3929 calibrator=HistogramCalibrator quant)\n",
      "layers.7.layers.0.quantizer             : TensorQuantizer(8bit per-tensor amax=1.5125 calibrator=HistogramCalibrator quant)\n",
      "layers.7.layers.0.quantizer_w           : TensorQuantizer(8bit per-tensor amax=0.5671 calibrator=HistogramCalibrator quant)\n",
      "layers.7.layers.3.quantizer             : TensorQuantizer(8bit per-tensor amax=3.0546 calibrator=HistogramCalibrator quant)\n",
      "layers.7.layers.3.quantizer_w           : TensorQuantizer(8bit per-tensor amax=0.3512 calibrator=HistogramCalibrator quant)\n",
      "layers.8.layers.0.quantizer             : TensorQuantizer(8bit per-tensor amax=1.4272 calibrator=HistogramCalibrator quant)\n",
      "layers.8.layers.0.quantizer_w           : TensorQuantizer(8bit per-tensor amax=0.5123 calibrator=HistogramCalibrator quant)\n",
      "layers.8.layers.3.quantizer             : TensorQuantizer(8bit per-tensor amax=2.9007 calibrator=HistogramCalibrator quant)\n",
      "layers.8.layers.3.quantizer_w           : TensorQuantizer(8bit per-tensor amax=0.2946 calibrator=HistogramCalibrator quant)\n",
      "layers.9.layers.0.quantizer             : TensorQuantizer(8bit per-tensor amax=1.3223 calibrator=HistogramCalibrator quant)\n",
      "layers.9.layers.0.quantizer_w           : TensorQuantizer(8bit per-tensor amax=0.5080 calibrator=HistogramCalibrator quant)\n",
      "layers.9.layers.3.quantizer             : TensorQuantizer(8bit per-tensor amax=2.5293 calibrator=HistogramCalibrator quant)\n",
      "layers.9.layers.3.quantizer_w           : TensorQuantizer(8bit per-tensor amax=0.2638 calibrator=HistogramCalibrator quant)\n",
      "layers.10.layers.0.quantizer            : TensorQuantizer(8bit per-tensor amax=1.3064 calibrator=HistogramCalibrator quant)\n",
      "layers.10.layers.0.quantizer_w          : TensorQuantizer(8bit per-tensor amax=0.4333 calibrator=HistogramCalibrator quant)\n",
      "layers.10.layers.3.quantizer            : TensorQuantizer(8bit per-tensor amax=2.1900 calibrator=HistogramCalibrator quant)\n",
      "layers.10.layers.3.quantizer_w          : TensorQuantizer(8bit per-tensor amax=0.2892 calibrator=HistogramCalibrator quant)\n",
      "layers.11.layers.0.quantizer            : TensorQuantizer(8bit per-tensor amax=1.3634 calibrator=HistogramCalibrator quant)\n",
      "layers.11.layers.0.quantizer_w          : TensorQuantizer(8bit per-tensor amax=0.3928 calibrator=HistogramCalibrator quant)\n",
      "layers.11.layers.3.quantizer            : TensorQuantizer(8bit per-tensor amax=2.3699 calibrator=HistogramCalibrator quant)\n",
      "layers.11.layers.3.quantizer_w          : TensorQuantizer(8bit per-tensor amax=0.2265 calibrator=HistogramCalibrator quant)\n",
      "layers.12.layers.0.quantizer            : TensorQuantizer(8bit per-tensor amax=1.1904 calibrator=HistogramCalibrator quant)\n",
      "layers.12.layers.0.quantizer_w          : TensorQuantizer(8bit per-tensor amax=0.2764 calibrator=HistogramCalibrator quant)\n",
      "layers.12.layers.3.quantizer            : TensorQuantizer(8bit per-tensor amax=2.1497 calibrator=HistogramCalibrator quant)\n",
      "layers.12.layers.3.quantizer_w          : TensorQuantizer(8bit per-tensor amax=0.1603 calibrator=HistogramCalibrator quant)\n"
     ]
    }
   ],
   "source": [
    "from pytorch_quantization import nn as quant_nn\n",
    "from pytorch_quantization import calib\n",
    "\n",
    "def collect_stats(model, data_loader, num_batches):\n",
    "     \"\"\"Feed data to the network and collect statistic\"\"\"\n",
    "\n",
    "     # Enable calibrators\n",
    "     for name, module in model.named_modules():\n",
    "         if isinstance(module, quant_nn.TensorQuantizer):\n",
    "             if module._calibrator is not None:\n",
    "                 module.disable_quant()\n",
    "                 module.enable_calib()\n",
    "             else:\n",
    "                 module.disable()\n",
    "\n",
    "     for i, (image, _) in tqdm(enumerate(data_loader), total=num_batches):\n",
    "         model(image.cpu())\n",
    "         if i >= num_batches:\n",
    "             break\n",
    "\n",
    "     # Disable calibrators\n",
    "     for name, module in model.named_modules():\n",
    "         if isinstance(module, quant_nn.TensorQuantizer):\n",
    "             if module._calibrator is not None:\n",
    "                 module.enable_quant()\n",
    "                 module.disable_calib()\n",
    "             else:\n",
    "                 module.enable()\n",
    "\n",
    "def compute_amax(model, **kwargs):\n",
    " # Load calib result\n",
    " for name, module in model.named_modules():\n",
    "     if isinstance(module, quant_nn.TensorQuantizer):\n",
    "         if module._calibrator is not None:\n",
    "             if isinstance(module._calibrator, calib.MaxCalibrator):\n",
    "                 module.load_calib_amax()\n",
    "             else:\n",
    "                 module.load_calib_amax(**kwargs)\n",
    "         print(F\"{name:40}: {module}\")\n",
    " model.cpu()\n",
    "\n",
    "# It is a bit slow since we collect histograms on CPU\n",
    "with torch.no_grad():\n",
    "    stats = collect_stats(model, data_t, num_batches=2)\n",
    "    amax = compute_amax(model, method=\"percentile\", percentile=99.99)\n",
    "    \n",
    "    # optional - test different calibration methods\n",
    "    #amax = compute_amax(model, method=\"mse\")\n",
    "    #amax = compute_amax(model, method=\"entropy\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2cedaacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from models.SDNs.wideresnet_sdn import WideResNet_SDN\n",
    "\n",
    "# torch.save(model.state_dict(), 'wideresnet_state_dict_sdnn.pth')\n",
    "\n",
    "# models = WideResNet_SDN()\n",
    "# torch.load('wideresnet_state_dict_sdnn.pth', map_location=\"cpu\")\n",
    "# # models = models.load_state_dict(torch.load('wideresnet_state_dict_sdnn.pth', map_location=\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2570157d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import timeit\n",
    "# correct = 0\n",
    "# total = 0\n",
    "\n",
    "# model.eval()\n",
    "# start_time = timeit.default_timer()\n",
    "# with torch.no_grad():\n",
    "#     for iteraction, (images, labels) in tqdm(enumerate(data), total=len(data)):\n",
    "#         images, labels = images.to(\"cpu\"), labels.to(\"cpu\")\n",
    "#         outputs = model(images)[-1]\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "# print(timeit.default_timer() - start_time)\n",
    "# print('Accuracy of the network on the 10000 test images: %.4f %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "851dddd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test the loaded model\n",
    "# # model.eval()\n",
    "# top1_test, top5_test, preds = fie.sdn_test_uncertainty(model, t_dataset.test_loader, \"cpu\")\n",
    "# print(\"Top-1 accuracy:\",top1_test)\n",
    "# print(\"Top-5 accuracy:\",top5_test)\n",
    "\n",
    "# # Sample prediction result\n",
    "# print(\"Correctly predicted?\",bool(preds[0][0]),\",Confidence:\",preds[0][1],\",Uncertainty:\",preds[0][2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9687d24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test early exit capability of the mend model with zero uncertainty threshold and confidence threshold of 0.8\n",
    "# # uncertainty_threshold = -10\n",
    "# # confidence_threshold = 0.6\n",
    "\n",
    "uncertainty_threshold = -8\n",
    "confidence_threshold = 0.5\n",
    "\n",
    "# fie.sdn_test_early_exits(model, one_batch_dataset.test_loader, confidence_threshold, uncertainty_threshold, \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ecba4f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import mul8s_1L2L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2945e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "\n",
    "def introduce_fault(model, percent_of_faults, fault_loc = None, layer_to_attack = None):\n",
    "    model.eval()\n",
    "    for name, param in model.named_parameters():\n",
    "        if name in layer_to_attack: \n",
    "        \n",
    "            print(\"Attacked layer\",name)\n",
    "            print(param.shape)\n",
    "            w1 = param.data\n",
    "            wf1 = torch.flatten(w1)\n",
    "            no_of_faults = int(percent_of_faults * len(wf1)/100)\n",
    "            if (no_of_faults > len(wf1)):\n",
    "                no_of_faults = len(wf1)\n",
    "\n",
    "            print(\"Number of weights attacked\", no_of_faults)\n",
    "            if fault_loc is None:\n",
    "                fault_loc = random.sample(range(0, len(wf1)), no_of_faults)\n",
    "                fault = [random.uniform(-2, 2) for _ in range(len(fault_loc))]\n",
    "                # print(\"fault location\", fault)\n",
    "            \n",
    "            for i in range(0, len(fault_loc)):\n",
    "                # print(f\"Fault values, before {wf1[fault_loc[i]]},   after: {-wf1[fault_loc[i]]}\")\n",
    "#                 wf1[fault_loc[i]] = -wf1[fault_loc[i]]\n",
    "                wf1[fault_loc[i]] = torch.tensor(fault[i])\n",
    "            \n",
    "            wf11 = wf1.reshape(w1.shape)\n",
    "            param.data = wf11\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1317f7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FP = ['layers.0.layers.0.weight'] # Example layers in vgg16\n",
    "# FP = ['layers.0.layers.1.0.weight','layers.0.layers.0.2.weight']# Example layers in wideresnet\n",
    "# FP = [\"init_conv.weight\"] # Example layers in wideresnet\n",
    "FP = [\"init_conv.0.weight\"] # Example layers in mobilenet\n",
    "\n",
    "FR = 10\n",
    "\n",
    "old_parameter = deepcopy(dict(model.named_parameters())[FP[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c46d653b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = introduce_fault(model, FR, None, FP)\n",
    "\n",
    "# top1_acc, top5_acc, early_output_counts, non_conf_output_counts, conf_violation_counts, unc_viol_with_fault = \\\n",
    "#   fie.sdn_test_early_exits(model, one_batch_dataset.test_loader, confidence_threshold, uncertainty_threshold, \"cpu\")\n",
    "\n",
    "# print(\"top1_acc, top5_acc, early_output_counts, non_conf_output_counts, conf_violation_counts, unc_viol_with_fault: \",\n",
    "#      top1_acc, top5_acc, early_output_counts, non_conf_output_counts, conf_violation_counts, unc_viol_with_fault)\n",
    "\n",
    "# top1_acc, top5_acc, early_output_counts, non_conf_output_counts, conf_violation_counts, unc_viol_with_fault:  \n",
    "#  45.65 88.35 [1350, 397, 185, 21, 23, 2, 0] [1, 0, 0, 0, 0, 0, 21] [650, 253, 68, 47, 24, 22, 3] [0, 0, 0, 0, 0, 0, 0]\n",
    "# top1_acc, top5_acc, early_output_counts, non_conf_output_counts, conf_violation_counts, unc_viol_with_fault: \n",
    "# 66.94 96.49 [7286, 915, 1310, 279, 141, 52, 0] [0, 0, 0, 0, 0, 1, 16] [2714, 1799, 489, 210, 69, 17, 0] [0, 0, 0, 0, 0, 0,\n",
    "\n",
    "# top1_acc, top5_acc, early_output_counts, non_conf_output_counts, conf_violation_counts, unc_viol_with_fault:  \n",
    "# 78.8 99.0 [677, 247, 70, 2, 3, 0, 0] [0, 0, 0, 0, 0, 0, 1] [323, 76, 6, 4, 1, 1, 0] [0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "# 61.9 93.9 [571, 284, 110, 8, 15, 1, 0] [0, 0, 0, 0, 0, 0, 11] [429, 145, 35, 27, 12, 11, 0] [0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "# 76.8 96.4 [1, 0, 196, 20, 119, 0, 0] [0, 0, 18, 1, 2, 0, 643] [0, 0, 0, 0, 0, 0, 0] [999, 999, 803, 783, 664, 664, 303]\n",
    "\n",
    "# 67.0 95.0 [0, 2, 15, 46, 4, 0] [0, 0, 0, 0, 0, 33] [0, 0, 0, 0, 0, 0] [100, 98, 83, 37, 33, 24]\n",
    "\n",
    "# 42.0 81.0 [0, 0, 0, 1, 2, 12, 0] [2, 2, 0, 2, 5, 13, 61] [0, 0, 0, 0, 0, 0, 0] [100, 100, 100, 99, 97, 85, 68]\n",
    "# 67.0 95.0 [0, 2, 15, 45, 5, 0] [0, 0, 0, 0, 0, 33] [0, 0, 0, 0, 0, 0] [100, 98, 83, 38, 33, 24]\n",
    "\n",
    "# 30.0 60.0 [9, 2, 1, 4, 8, 0] [0, 0, 0, 0, 0, 76] [2, 0, 1, 1, 0, 21] [91, 91, 87, 83, 76, 1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af0d96ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attacked layer init_conv.0.weight\n",
      "torch.Size([32, 3, 3, 3])\n",
      "Number of weights attacked 86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/adapt/examples/models/SDNs/sdm_fault_mitigation.py:90: UserWarning: p-value capped: true value larger than 0.25\n",
      "  result = stats.anderson_ksamp([self.initial_stats[layer_name]['sample'], current_sample])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is there any correction:  Nothing\n"
     ]
    }
   ],
   "source": [
    "model, correction = sdm.introduce_fault_with_sdm(model, FR, None, FP)\n",
    "# model = introduce_fault(model, FR, None, FP[0])\n",
    "print(\"Is there any correction: \", correction if correction else \"Nothing\")\n",
    "new_parameter = dict(model.named_parameters())[FP[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594fc5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   7%|████████████████▌                                                                                                                                                                                                                           | 7/100 [00:01<00:19,  4.70it/s]"
     ]
    }
   ],
   "source": [
    "top1_acc, top5_acc, early_output_counts, non_conf_output_counts, conf_violation_counts, unc_viol_with_fault = \\\n",
    "  sdm.sdn_test_early_exits_sdm(model, one_batch_dataset.test_loader, confidence_threshold, uncertainty_threshold, \"cpu\")\n",
    "\n",
    "print(\"top1_acc, top5_acc, early_output_counts, non_conf_output_counts, conf_violation_counts, unc_viol_with_fault: \",\n",
    "     top1_acc, top5_acc, early_output_counts, non_conf_output_counts, conf_violation_counts, unc_viol_with_fault)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a06f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.equal(old_parameter, new_parameter)\n",
    "# old_parameter == new_parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d8829f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.equal(old_parameter, new_parameter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93c2780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare tensors element-wise and count unequal elements\n",
    "unequal_count = torch.sum(torch.ne(old_parameter, new_parameter)).item()\n",
    "\n",
    "print(f'Number of unequal parameters: {unequal_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52605ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
