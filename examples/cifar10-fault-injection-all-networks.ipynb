{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98a115dd",
   "metadata": {},
   "source": [
    "# Model evaluation and re-training with AdaPT on Cifar10 dataset\n",
    "\n",
    "In this notebook you can evaluate different approximate multipliers on various models based on Cifar10 dataset\n",
    "\n",
    "Steps:\n",
    "* Select models to load \n",
    "* Select number of threads to use\n",
    "* Choose approximate multiplier \n",
    "* Load model for evaluation\n",
    "* Load dataset\n",
    "* Run model calibration for quantization\n",
    "* Run model evaluation\n",
    "* Run approximate-aware re-training\n",
    "* Rerun model evaluation\n",
    "\n",
    "**Note**:\n",
    "* This notebook should be run on a X86 machine\n",
    "\n",
    "* Please make sure you have run the installation steps first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5eef0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import requests\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms as T\n",
    "from torchvision.datasets import CIFAR10\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5d4c7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_seed():\n",
    "    return 1221 # 121 and 1221\n",
    "\n",
    "def set_random_seeds():\n",
    "    torch.manual_seed(get_random_seed())\n",
    "    np.random.seed(get_random_seed())\n",
    "    random.seed(get_random_seed())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab49b35",
   "metadata": {},
   "source": [
    "## Select models to load \n",
    "\n",
    "The weights must be downloaded in state_dicts folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "183a13aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.SDNs.vgg_sdn import vgg16_sdn_bn\n",
    "from models.SDNs.wideresnet_sdn import wideresnet_sdn_v1\n",
    "from models.SDNs.mobilenet_sdn import mobilenet_sdn_v1\n",
    "import models.SDNs.fault_injection as fie\n",
    "import models.SDNs.sdm_fault_mitigation as sdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69265983",
   "metadata": {},
   "source": [
    "## Select number of threads to use\n",
    "\n",
    "For optimal performance set them as the number of your cpu threads (not cpu cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "165c2d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: OMP_PLACES=cores\n",
      "env: OMP_PROC_BIND=close\n",
      "env: OMP_WAIT_POLICY=active\n"
     ]
    }
   ],
   "source": [
    "threads = 20\n",
    "torch.set_num_threads(threads)\n",
    "\n",
    "# maybe better performance\n",
    "%env OMP_PLACES=cores\n",
    "%env OMP_PROC_BIND=close\n",
    "%env OMP_WAIT_POLICY=active"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa06300",
   "metadata": {},
   "source": [
    "## Choose approximate multiplier \n",
    "\n",
    "Two approximate multipliers are already provided\n",
    "\n",
    "**mul8s_acc** - (header file: mul8s_acc.h)   <--  default\n",
    "\n",
    "**mul8s_1L2H** - (header file: mul8s_1L2H.h)\n",
    "\n",
    "\n",
    "\n",
    "In order to use your custom multiplier you need to use the provided tool (LUT_generator) to easily create the C++ header for your multiplier. Then you just place it inside the adapt/cpu-kernels/axx_mults folder. The name of the axx_mult here must match the name of the header file. The same axx_mult is used in all layers. \n",
    "\n",
    "Tip: If you want explicitly to set for each layer a different axx_mult you must do it from the model definition using the respective AdaPT_Conv2d class of each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "562689c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# axx_mult = 'mul8s_acc'\n",
    "axx_mult = 'mul8s_1KV6'\n",
    "# axx_mult = 'mul8s_1KV8'\n",
    "# axx_mult = 'mul8s_1KV9'\n",
    "# axx_mult = 'mul8s_1KVP'\n",
    "# axx_mult = 'mul8s_1L2J'\n",
    "# axx_mult = 'mul8s_1L2H'\n",
    "# axx_mult = 'mul8s_1L2N'\n",
    "# axx_mult = 'mul8s_1L12'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b539e7e1",
   "metadata": {},
   "source": [
    "## Load model for evaluation\n",
    "\n",
    "Jit compilation method loads 'on the fly' the C++ extentions of the approximate multipliers. Then the pytorch model is loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc26796f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "Emitting ninja build file /root/.cache/torch_extensions/PyInit_conv2d_mul8s_1KV6/build.ninja...\n",
      "Building extension module PyInit_conv2d_mul8s_1KV6...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module PyInit_conv2d_mul8s_1KV6...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1KV6, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1KV6...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1KV6, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1KV6...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1KV6, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1KV6...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1KV6, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1KV6...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1KV6, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1KV6...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1KV6, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1KV6...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1KV6, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1KV6...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1KV6, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1KV6...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1KV6, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1KV6...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1KV6, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1KV6...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1KV6, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1KV6...\n",
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module PyInit_conv2d_mul8s_1KV6, skipping build step...\n",
      "Loading extension module PyInit_conv2d_mul8s_1KV6...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VGG_SDN(\n",
       "  (init_conv): Sequential()\n",
       "  (layers): ModuleList(\n",
       "    (0): ConvBlockWOutput(\n",
       "      (layers): Sequential(\n",
       "        (0): AdaPT_Conv2d(\n",
       "          3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "          (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "          (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        )\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (output): Sequential()\n",
       "    )\n",
       "    (1): ConvBlockWOutput(\n",
       "      (layers): Sequential(\n",
       "        (0): AdaPT_Conv2d(\n",
       "          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "          (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "          (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        )\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (output): InternalClassifier(\n",
       "        (max_pool): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "        (avg_pool): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
       "        (linear): Linear(in_features=1024, out_features=10, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (2): ConvBlockWOutput(\n",
       "      (layers): Sequential(\n",
       "        (0): AdaPT_Conv2d(\n",
       "          64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "          (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "          (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        )\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (output): Sequential()\n",
       "    )\n",
       "    (3): ConvBlockWOutput(\n",
       "      (layers): Sequential(\n",
       "        (0): AdaPT_Conv2d(\n",
       "          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "          (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "          (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        )\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (output): InternalClassifier(\n",
       "        (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (avg_pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        (linear): Linear(in_features=2048, out_features=10, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (4): ConvBlockWOutput(\n",
       "      (layers): Sequential(\n",
       "        (0): AdaPT_Conv2d(\n",
       "          128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "          (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "          (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        )\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (output): Sequential()\n",
       "    )\n",
       "    (5): ConvBlockWOutput(\n",
       "      (layers): Sequential(\n",
       "        (0): AdaPT_Conv2d(\n",
       "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "          (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "          (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        )\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (output): InternalClassifier(\n",
       "        (max_pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (avg_pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        (linear): Linear(in_features=4096, out_features=10, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (6): ConvBlockWOutput(\n",
       "      (layers): Sequential(\n",
       "        (0): AdaPT_Conv2d(\n",
       "          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "          (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "          (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        )\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (output): InternalClassifier(\n",
       "        (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "        (avg_pool): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
       "        (linear): Linear(in_features=4096, out_features=10, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (7): ConvBlockWOutput(\n",
       "      (layers): Sequential(\n",
       "        (0): AdaPT_Conv2d(\n",
       "          256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "          (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "          (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        )\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (output): Sequential()\n",
       "    )\n",
       "    (8): ConvBlockWOutput(\n",
       "      (layers): Sequential(\n",
       "        (0): AdaPT_Conv2d(\n",
       "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "          (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "          (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        )\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (output): InternalClassifier(\n",
       "        (max_pool): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "        (avg_pool): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
       "        (linear): Linear(in_features=8192, out_features=10, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (9): ConvBlockWOutput(\n",
       "      (layers): Sequential(\n",
       "        (0): AdaPT_Conv2d(\n",
       "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "          (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "          (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        )\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (output): InternalClassifier(\n",
       "        (linear): Linear(in_features=2048, out_features=10, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (10): ConvBlockWOutput(\n",
       "      (layers): Sequential(\n",
       "        (0): AdaPT_Conv2d(\n",
       "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "          (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "          (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        )\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (output): Sequential()\n",
       "    )\n",
       "    (11): ConvBlockWOutput(\n",
       "      (layers): Sequential(\n",
       "        (0): AdaPT_Conv2d(\n",
       "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "          (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "          (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        )\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (output): Sequential()\n",
       "    )\n",
       "    (12): ConvBlockWOutput(\n",
       "      (layers): Sequential(\n",
       "        (0): AdaPT_Conv2d(\n",
       "          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "          (quantizer): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "          (quantizer_w): TensorQuantizer(8bit per-tensor amax=dynamic calibrator=HistogramCalibrator quant)\n",
       "        )\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (output): Sequential()\n",
       "    )\n",
       "    (13): FcBlockWOutput(\n",
       "      (layers): Sequential(\n",
       "        (0): Flatten(start_dim=1, end_dim=-1)\n",
       "        (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (2): ReLU()\n",
       "        (3): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "      (output): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (end_layers): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (1): Dropout(p=0.5, inplace=False)\n",
       "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = vgg16_sdn_bn(pretrained=True, axx_mult = axx_mult)\n",
    "# model = wideresnet_sdn_v1(pretrained=True, axx_mult = axx_mult)\n",
    "# model = mobilenet_sdn_v1(pretrained=True, axx_mult = axx_mult)\n",
    "\n",
    "model.eval() # for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7de58a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "init_conv\n",
      "layers\n",
      "layers.0\n",
      "layers.0.layers\n",
      "layers.0.layers.0\n",
      "layers.0.layers.0.quantizer\n",
      "layers.0.layers.0.quantizer_w\n",
      "layers.0.layers.1\n",
      "layers.0.layers.2\n",
      "layers.0.output\n",
      "layers.1\n",
      "layers.1.layers\n",
      "layers.1.layers.0\n",
      "layers.1.layers.0.quantizer\n",
      "layers.1.layers.0.quantizer_w\n",
      "layers.1.layers.1\n",
      "layers.1.layers.2\n",
      "layers.1.layers.3\n",
      "layers.1.output\n",
      "layers.1.output.max_pool\n",
      "layers.1.output.avg_pool\n",
      "layers.1.output.linear\n",
      "layers.2\n",
      "layers.2.layers\n",
      "layers.2.layers.0\n",
      "layers.2.layers.0.quantizer\n",
      "layers.2.layers.0.quantizer_w\n",
      "layers.2.layers.1\n",
      "layers.2.layers.2\n",
      "layers.2.output\n",
      "layers.3\n",
      "layers.3.layers\n",
      "layers.3.layers.0\n",
      "layers.3.layers.0.quantizer\n",
      "layers.3.layers.0.quantizer_w\n",
      "layers.3.layers.1\n",
      "layers.3.layers.2\n",
      "layers.3.layers.3\n",
      "layers.3.output\n",
      "layers.3.output.max_pool\n",
      "layers.3.output.avg_pool\n",
      "layers.3.output.linear\n",
      "layers.4\n",
      "layers.4.layers\n",
      "layers.4.layers.0\n",
      "layers.4.layers.0.quantizer\n",
      "layers.4.layers.0.quantizer_w\n",
      "layers.4.layers.1\n",
      "layers.4.layers.2\n",
      "layers.4.output\n",
      "layers.5\n",
      "layers.5.layers\n",
      "layers.5.layers.0\n",
      "layers.5.layers.0.quantizer\n",
      "layers.5.layers.0.quantizer_w\n",
      "layers.5.layers.1\n",
      "layers.5.layers.2\n",
      "layers.5.output\n",
      "layers.5.output.max_pool\n",
      "layers.5.output.avg_pool\n",
      "layers.5.output.linear\n",
      "layers.6\n",
      "layers.6.layers\n",
      "layers.6.layers.0\n",
      "layers.6.layers.0.quantizer\n",
      "layers.6.layers.0.quantizer_w\n",
      "layers.6.layers.1\n",
      "layers.6.layers.2\n",
      "layers.6.layers.3\n",
      "layers.6.output\n",
      "layers.6.output.max_pool\n",
      "layers.6.output.avg_pool\n",
      "layers.6.output.linear\n",
      "layers.7\n",
      "layers.7.layers\n",
      "layers.7.layers.0\n",
      "layers.7.layers.0.quantizer\n",
      "layers.7.layers.0.quantizer_w\n",
      "layers.7.layers.1\n",
      "layers.7.layers.2\n",
      "layers.7.output\n",
      "layers.8\n",
      "layers.8.layers\n",
      "layers.8.layers.0\n",
      "layers.8.layers.0.quantizer\n",
      "layers.8.layers.0.quantizer_w\n",
      "layers.8.layers.1\n",
      "layers.8.layers.2\n",
      "layers.8.output\n",
      "layers.8.output.max_pool\n",
      "layers.8.output.avg_pool\n",
      "layers.8.output.linear\n",
      "layers.9\n",
      "layers.9.layers\n",
      "layers.9.layers.0\n",
      "layers.9.layers.0.quantizer\n",
      "layers.9.layers.0.quantizer_w\n",
      "layers.9.layers.1\n",
      "layers.9.layers.2\n",
      "layers.9.layers.3\n",
      "layers.9.output\n",
      "layers.9.output.linear\n",
      "layers.10\n",
      "layers.10.layers\n",
      "layers.10.layers.0\n",
      "layers.10.layers.0.quantizer\n",
      "layers.10.layers.0.quantizer_w\n",
      "layers.10.layers.1\n",
      "layers.10.layers.2\n",
      "layers.10.output\n",
      "layers.11\n",
      "layers.11.layers\n",
      "layers.11.layers.0\n",
      "layers.11.layers.0.quantizer\n",
      "layers.11.layers.0.quantizer_w\n",
      "layers.11.layers.1\n",
      "layers.11.layers.2\n",
      "layers.11.output\n",
      "layers.12\n",
      "layers.12.layers\n",
      "layers.12.layers.0\n",
      "layers.12.layers.0.quantizer\n",
      "layers.12.layers.0.quantizer_w\n",
      "layers.12.layers.1\n",
      "layers.12.layers.2\n",
      "layers.12.layers.3\n",
      "layers.12.output\n",
      "layers.13\n",
      "layers.13.layers\n",
      "layers.13.layers.0\n",
      "layers.13.layers.1\n",
      "layers.13.layers.2\n",
      "layers.13.layers.3\n",
      "layers.13.output\n",
      "end_layers\n",
      "end_layers.0\n",
      "end_layers.1\n",
      "end_layers.2\n"
     ]
    }
   ],
   "source": [
    "# Set random seeds\n",
    "set_random_seeds()\n",
    "\n",
    "# Print names of immediate layers only\n",
    "for name, layer in model.named_modules():\n",
    "    print(name)\n",
    "    \n",
    "# layers.0.layers.0.quantizer\n",
    "# layers.0.layers.0.quantizer_w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df592b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set random seeds\n",
    "# set_random_seeds()\n",
    "# from scipy import stats\n",
    "# from adapt.approx_layers import axx_layers as approxNN\n",
    "\n",
    "# check_layer = \"init_conv.weight\"\n",
    "# initial_stats = {}\n",
    "# # Print names of immediate layers only\n",
    "# for name, module in model.named_modules():\n",
    "#     print(name)\n",
    "#     if isinstance(module, approxNN.AdaPT_Conv2d) and name in check_layer:\n",
    "#         print(\"This\")\n",
    "#         weights = module.weight.data.cpu().numpy().flatten()\n",
    "#         initial_stats[name] = {\n",
    "#             'mean': np.mean(weights),\n",
    "#             'std': np.std(weights),\n",
    "#             'sample': np.random.choice(weights, size=100, replace=False)\n",
    "#         }\n",
    "#         print(\"length: \", len(weights))\n",
    "#         break\n",
    "\n",
    "\n",
    "# module = dict(model.named_modules())[name]\n",
    "# current_weights = module.weight.data.cpu().numpy().flatten()\n",
    "# current_sample = np.random.choice(current_weights, size=100, replace=False)\n",
    "\n",
    "# ks_statistic, p_value = stats.ks_2samp(initial_stats[name]['sample'], current_sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76721ed0",
   "metadata": {},
   "source": [
    "## Load dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f63b4701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "def val_dataloader(mean = (0.4914, 0.4822, 0.4465), std = (0.2471, 0.2435, 0.2616)):\n",
    "\n",
    "    transform = T.Compose(\n",
    "        [\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean, std),\n",
    "        ]\n",
    "    )\n",
    "    dataset = CIFAR10(root=\"datasets/cifar10_data\", train=False, download=True, transform=transform)\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=128,\n",
    "        num_workers=0,\n",
    "        drop_last=True,\n",
    "        pin_memory=False,\n",
    "    )\n",
    "    return dataloader\n",
    "\n",
    "transform = T.Compose(\n",
    "        [\n",
    "            T.RandomCrop(32, padding=4),\n",
    "            T.RandomHorizontalFlip(),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225)),\n",
    "        ]\n",
    "    )\n",
    "dataset = CIFAR10(root=\"datasets/cifar10_data\", train=True, download=True, transform=transform)\n",
    "\n",
    "evens = list(range(0, len(dataset), 10))\n",
    "trainset_1 = torch.utils.data.Subset(dataset, evens)\n",
    "\n",
    "data = val_dataloader()\n",
    "\n",
    "# data_t is used for calibration purposes and is a subset of train-set\n",
    "data_t = DataLoader(trainset_1, batch_size=128,\n",
    "                                            shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47aa7856",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cifar10_:\n",
    "    def __init__(self, batch_size=128, add_trigger=False):\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = 32\n",
    "        self.num_classes = 10\n",
    "        self.num_test = 10000  # Set the number of test samples to 2000\n",
    "        self.num_train = 50000\n",
    "\n",
    "        normalize = T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        self.augmented = T.Compose([T.RandomHorizontalFlip(), T.RandomCrop(32, padding=4), T.ToTensor(), normalize])\n",
    "        self.normalized = T.Compose([T.ToTensor(), normalize])\n",
    "\n",
    "        self.aug_trainset = CIFAR10(root='datasets/cifar10_data', train=True, download=False, transform=self.augmented)\n",
    "        self.aug_train_loader = torch.utils.data.DataLoader(self.aug_trainset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "        self.trainset = CIFAR10(root='datasets/cifar10_data', train=True, download=False, transform=self.normalized)\n",
    "        self.train_loader = torch.utils.data.DataLoader(self.trainset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        # Load the full test set\n",
    "        self.full_testset = CIFAR10(root='datasets/cifar10_data', train=False, download=False, transform=self.normalized)\n",
    "        \n",
    "        indices = np.random.choice(len(self.full_testset), self.num_test, replace=False)\n",
    "        \n",
    "        # Create a subset of the test set with these indices\n",
    "        self.testset = torch.utils.data.Subset(self.full_testset, indices)\n",
    "        self.test_loader = torch.utils.data.DataLoader(self.testset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "def load_cifar10(batch_size, add_trigger=False):\n",
    "    cifar10_data = Cifar10_(batch_size=batch_size, add_trigger=add_trigger)\n",
    "    return cifar10_data\n",
    "\n",
    "def get_dataset(batch_size=128, add_trigger=False):\n",
    "    return load_cifar10(batch_size, add_trigger)\n",
    "\n",
    "t_dataset = get_dataset()\n",
    "one_batch_dataset = get_dataset(1, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa74c5d",
   "metadata": {},
   "source": [
    "## Run model calibration for quantization\n",
    "\n",
    "Calibrates the quantization parameters \n",
    "\n",
    "Need to re-run it each time the model changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "946f0d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:04<00:00,  2.22s/it]\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0912 21:47:15.828144 140116564219712 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0912 21:47:15.828538 140116564219712 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0912 21:47:15.828826 140116564219712 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0912 21:47:15.829401 140116564219712 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0912 21:47:15.829720 140116564219712 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0912 21:47:15.829999 140116564219712 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0912 21:47:15.830278 140116564219712 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0912 21:47:15.830548 140116564219712 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0912 21:47:15.830831 140116564219712 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0912 21:47:15.831097 140116564219712 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0912 21:47:15.831371 140116564219712 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0912 21:47:15.831633 140116564219712 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0912 21:47:15.831914 140116564219712 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0912 21:47:15.832179 140116564219712 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0912 21:47:15.832453 140116564219712 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0912 21:47:15.832717 140116564219712 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0912 21:47:15.832994 140116564219712 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0912 21:47:15.834106 140116564219712 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0912 21:47:15.834391 140116564219712 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0912 21:47:15.834660 140116564219712 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0912 21:47:15.834933 140116564219712 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0912 21:47:15.835468 140116564219712 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0912 21:47:15.835744 140116564219712 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0912 21:47:15.836017 140116564219712 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0912 21:47:15.836283 140116564219712 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0912 21:47:15.836547 140116564219712 tensor_quantizer.py:173] Disable HistogramCalibrator\n",
      "W0912 21:47:15.837307 140116564219712 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0912 21:47:15.837713 140116564219712 tensor_quantizer.py:238] Call .cuda() if running on GPU after loading calibrated amax.\n",
      "W0912 21:47:15.838366 140116564219712 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0912 21:47:15.838915 140116564219712 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0912 21:47:15.839418 140116564219712 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0912 21:47:15.839779 140116564219712 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0912 21:47:15.840146 140116564219712 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0912 21:47:15.840906 140116564219712 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0912 21:47:15.841445 140116564219712 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0912 21:47:15.841811 140116564219712 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0912 21:47:15.842386 140116564219712 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0912 21:47:15.842734 140116564219712 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0912 21:47:15.843303 140116564219712 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0912 21:47:15.843650 140116564219712 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0912 21:47:15.844223 140116564219712 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0912 21:47:15.844574 140116564219712 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0912 21:47:15.844915 140116564219712 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0912 21:47:15.845273 140116564219712 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0912 21:47:15.846045 140116564219712 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0912 21:47:15.846400 140116564219712 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0912 21:47:15.846946 140116564219712 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0912 21:47:15.847400 140116564219712 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0912 21:47:15.847838 140116564219712 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0912 21:47:15.848284 140116564219712 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0912 21:47:15.848723 140116564219712 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0912 21:47:15.849052 140116564219712 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n",
      "W0912 21:47:15.849383 140116564219712 tensor_quantizer.py:237] Load calibrated amax, shape=torch.Size([]).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.layers.0.quantizer             : TensorQuantizer(8bit per-tensor amax=2.6387 calibrator=HistogramCalibrator quant)\n",
      "layers.0.layers.0.quantizer_w           : TensorQuantizer(8bit per-tensor amax=0.9820 calibrator=HistogramCalibrator quant)\n",
      "layers.1.layers.0.quantizer             : TensorQuantizer(8bit per-tensor amax=3.5563 calibrator=HistogramCalibrator quant)\n",
      "layers.1.layers.0.quantizer_w           : TensorQuantizer(8bit per-tensor amax=0.3465 calibrator=HistogramCalibrator quant)\n",
      "layers.2.layers.0.quantizer             : TensorQuantizer(8bit per-tensor amax=2.7118 calibrator=HistogramCalibrator quant)\n",
      "layers.2.layers.0.quantizer_w           : TensorQuantizer(8bit per-tensor amax=0.2154 calibrator=HistogramCalibrator quant)\n",
      "layers.3.layers.0.quantizer             : TensorQuantizer(8bit per-tensor amax=1.1159 calibrator=HistogramCalibrator quant)\n",
      "layers.3.layers.0.quantizer_w           : TensorQuantizer(8bit per-tensor amax=0.1585 calibrator=HistogramCalibrator quant)\n",
      "layers.4.layers.0.quantizer             : TensorQuantizer(8bit per-tensor amax=1.4125 calibrator=HistogramCalibrator quant)\n",
      "layers.4.layers.0.quantizer_w           : TensorQuantizer(8bit per-tensor amax=0.1386 calibrator=HistogramCalibrator quant)\n",
      "layers.5.layers.0.quantizer             : TensorQuantizer(8bit per-tensor amax=1.0222 calibrator=HistogramCalibrator quant)\n",
      "layers.5.layers.0.quantizer_w           : TensorQuantizer(8bit per-tensor amax=0.0936 calibrator=HistogramCalibrator quant)\n",
      "layers.6.layers.0.quantizer             : TensorQuantizer(8bit per-tensor amax=0.9392 calibrator=HistogramCalibrator quant)\n",
      "layers.6.layers.0.quantizer_w           : TensorQuantizer(8bit per-tensor amax=0.0888 calibrator=HistogramCalibrator quant)\n",
      "layers.7.layers.0.quantizer             : TensorQuantizer(8bit per-tensor amax=1.3209 calibrator=HistogramCalibrator quant)\n",
      "layers.7.layers.0.quantizer_w           : TensorQuantizer(8bit per-tensor amax=0.0513 calibrator=HistogramCalibrator quant)\n",
      "layers.8.layers.0.quantizer             : TensorQuantizer(8bit per-tensor amax=0.8902 calibrator=HistogramCalibrator quant)\n",
      "layers.8.layers.0.quantizer_w           : TensorQuantizer(8bit per-tensor amax=0.0278 calibrator=HistogramCalibrator quant)\n",
      "layers.9.layers.0.quantizer             : TensorQuantizer(8bit per-tensor amax=0.6797 calibrator=HistogramCalibrator quant)\n",
      "layers.9.layers.0.quantizer_w           : TensorQuantizer(8bit per-tensor amax=0.0263 calibrator=HistogramCalibrator quant)\n",
      "layers.10.layers.0.quantizer            : TensorQuantizer(8bit per-tensor amax=0.5399 calibrator=HistogramCalibrator quant)\n",
      "layers.10.layers.0.quantizer_w          : TensorQuantizer(8bit per-tensor amax=0.0196 calibrator=HistogramCalibrator quant)\n",
      "layers.11.layers.0.quantizer            : TensorQuantizer(8bit per-tensor amax=0.4221 calibrator=HistogramCalibrator quant)\n",
      "layers.11.layers.0.quantizer_w          : TensorQuantizer(8bit per-tensor amax=0.0254 calibrator=HistogramCalibrator quant)\n",
      "layers.12.layers.0.quantizer            : TensorQuantizer(8bit per-tensor amax=0.5201 calibrator=HistogramCalibrator quant)\n",
      "layers.12.layers.0.quantizer_w          : TensorQuantizer(8bit per-tensor amax=0.0388 calibrator=HistogramCalibrator quant)\n"
     ]
    }
   ],
   "source": [
    "from pytorch_quantization import nn as quant_nn\n",
    "from pytorch_quantization import calib\n",
    "\n",
    "def collect_stats(model, data_loader, num_batches):\n",
    "     \"\"\"Feed data to the network and collect statistic\"\"\"\n",
    "\n",
    "     # Enable calibrators\n",
    "     for name, module in model.named_modules():\n",
    "         if isinstance(module, quant_nn.TensorQuantizer):\n",
    "             if module._calibrator is not None:\n",
    "                 module.disable_quant()\n",
    "                 module.enable_calib()\n",
    "             else:\n",
    "                 module.disable()\n",
    "\n",
    "     for i, (image, _) in tqdm(enumerate(data_loader), total=num_batches):\n",
    "         model(image.cpu())\n",
    "         if i >= num_batches:\n",
    "             break\n",
    "\n",
    "     # Disable calibrators\n",
    "     for name, module in model.named_modules():\n",
    "         if isinstance(module, quant_nn.TensorQuantizer):\n",
    "             if module._calibrator is not None:\n",
    "                 module.enable_quant()\n",
    "                 module.disable_calib()\n",
    "             else:\n",
    "                 module.enable()\n",
    "\n",
    "def compute_amax(model, **kwargs):\n",
    " # Load calib result\n",
    " for name, module in model.named_modules():\n",
    "     if isinstance(module, quant_nn.TensorQuantizer):\n",
    "         if module._calibrator is not None:\n",
    "             if isinstance(module._calibrator, calib.MaxCalibrator):\n",
    "                 module.load_calib_amax()\n",
    "             else:\n",
    "                 module.load_calib_amax(**kwargs)\n",
    "         print(F\"{name:40}: {module}\")\n",
    " model.cpu()\n",
    "\n",
    "# It is a bit slow since we collect histograms on CPU\n",
    "with torch.no_grad():\n",
    "    stats = collect_stats(model, data_t, num_batches=2)\n",
    "    amax = compute_amax(model, method=\"percentile\", percentile=99.99)\n",
    "    \n",
    "    # optional - test different calibration methods\n",
    "    #amax = compute_amax(model, method=\"mse\")\n",
    "    #amax = compute_amax(model, method=\"entropy\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2cedaacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from models.SDNs.wideresnet_sdn import WideResNet_SDN\n",
    "\n",
    "# torch.save(model.state_dict(), 'wideresnet_state_dict_sdnn.pth')\n",
    "\n",
    "# models = WideResNet_SDN()\n",
    "# torch.load('wideresnet_state_dict_sdnn.pth', map_location=\"cpu\")\n",
    "# # models = models.load_state_dict(torch.load('wideresnet_state_dict_sdnn.pth', map_location=\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2570157d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import timeit\n",
    "# correct = 0\n",
    "# total = 0\n",
    "\n",
    "# model.eval()\n",
    "# start_time = timeit.default_timer()\n",
    "# with torch.no_grad():\n",
    "#     for iteraction, (images, labels) in tqdm(enumerate(data), total=len(data)):\n",
    "#         images, labels = images.to(\"cpu\"), labels.to(\"cpu\")\n",
    "#         outputs = model(images)[-1]\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "# print(timeit.default_timer() - start_time)\n",
    "# print('Accuracy of the network on the 10000 test images: %.4f %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "851dddd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test the loaded model\n",
    "# # model.eval()\n",
    "# top1_test, top5_test, preds = fie.sdn_test_uncertainty(model, t_dataset.test_loader, \"cpu\")\n",
    "# print(\"Top-1 accuracy:\",top1_test)\n",
    "# print(\"Top-5 accuracy:\",top5_test)\n",
    "\n",
    "# # Sample prediction result\n",
    "# print(\"Correctly predicted?\",bool(preds[0][0]),\",Confidence:\",preds[0][1],\",Uncertainty:\",preds[0][2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9687d24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test early exit capability of the mend model with zero uncertainty threshold and confidence threshold of 0.8\n",
    "# # uncertainty_threshold = -10\n",
    "# # confidence_threshold = 0.6\n",
    "\n",
    "uncertainty_threshold = 8\n",
    "confidence_threshold = 0.5\n",
    "\n",
    "# fie.sdn_test_early_exits(model, one_batch_dataset.test_loader, confidence_threshold, uncertainty_threshold, \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ecba4f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import mul8s_1L2L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2945e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "\n",
    "def introduce_fault(model, percent_of_faults, fault_loc = None, layer_to_attack = None):\n",
    "    model.eval()\n",
    "    for name, param in model.named_parameters():\n",
    "        if name in layer_to_attack: \n",
    "        \n",
    "            print(\"Attacked layer\",name)\n",
    "            print(param.shape)\n",
    "            w1 = param.data\n",
    "            wf1 = torch.flatten(w1)\n",
    "            no_of_faults = int(percent_of_faults * len(wf1)/100)\n",
    "            if (no_of_faults > len(wf1)):\n",
    "                no_of_faults = len(wf1)\n",
    "\n",
    "            print(\"Number of weights attacked\", no_of_faults)\n",
    "            if fault_loc is None:\n",
    "                fault_loc = random.sample(range(0, len(wf1)), no_of_faults)\n",
    "                fault = [random.uniform(-2, 2) for _ in range(len(fault_loc))]\n",
    "                # print(\"fault location\", fault)\n",
    "            \n",
    "            for i in range(0, len(fault_loc)):\n",
    "                # print(f\"Fault values, before {wf1[fault_loc[i]]},   after: {-wf1[fault_loc[i]]}\")\n",
    "                # wf1[fault_loc[i]] = -wf1[fault_loc[i]]\n",
    "                wf1[fault_loc[i]] = torch.tensor(fault[i])\n",
    "            \n",
    "            wf11 = wf1.reshape(w1.shape)\n",
    "            param.data = wf11\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1317f7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "FP = ['layers.0.layers.0.weight'] # Example layers in vgg16\n",
    "# FP = ['layers.0.layers.1.0.weight','layers.0.layers.0.2.weight']# Example layers in wideresnet\n",
    "# FP = [\"init_conv.weight\"] # Example layers in wideresnet\n",
    "# FP = [\"init_conv.0.weight\"] # Example layers in mobilenet\n",
    "\n",
    "FR = 30\n",
    "\n",
    "# model = introduce_fault(model, FR, None, FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c46d653b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top1_acc, top5_acc, early_output_counts, non_conf_output_counts, conf_violation_counts, unc_viol_with_fault = \\\n",
    "#   fie.sdn_test_early_exits(model, one_batch_dataset.test_loader, confidence_threshold, uncertainty_threshold, \"cpu\")\n",
    "\n",
    "# print(\"top1_acc, top5_acc, early_output_counts, non_conf_output_counts, conf_violation_counts, unc_viol_with_fault: \",\n",
    "#      top1_acc, top5_acc, early_output_counts, non_conf_output_counts, conf_violation_counts, unc_viol_with_fault)\n",
    "\n",
    "# top1_acc, top5_acc, early_output_counts, non_conf_output_counts, conf_violation_counts, unc_viol_with_fault:  \n",
    "#  45.65 88.35 [1350, 397, 185, 21, 23, 2, 0] [1, 0, 0, 0, 0, 0, 21] [650, 253, 68, 47, 24, 22, 3] [0, 0, 0, 0, 0, 0, 0]\n",
    "# top1_acc, top5_acc, early_output_counts, non_conf_output_counts, conf_violation_counts, unc_viol_with_fault: \n",
    "# 66.94 96.49 [7286, 915, 1310, 279, 141, 52, 0] [0, 0, 0, 0, 0, 1, 16] [2714, 1799, 489, 210, 69, 17, 0] [0, 0, 0, 0, 0, 0,\n",
    "\n",
    "# top1_acc, top5_acc, early_output_counts, non_conf_output_counts, conf_violation_counts, unc_viol_with_fault:  \n",
    "# 78.8 99.0 [677, 247, 70, 2, 3, 0, 0] [0, 0, 0, 0, 0, 0, 1] [323, 76, 6, 4, 1, 1, 0] [0, 0, 0, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af0d96ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attacked layer layers.0.layers.0.weight\n",
      "torch.Size([64, 3, 3, 3])\n",
      "Number of weights attacked 518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/adapt/examples/models/SDNs/sdm_fault_mitigation.py:90: UserWarning: p-value floored: true value smaller than 0.001\n",
      "  result = stats.anderson_ksamp([self.initial_stats[layer_name]['sample'], current_sample])\n",
      "/workspace/adapt/examples/models/SDNs/sdm_fault_mitigation.py:90: UserWarning: p-value capped: true value larger than 0.25\n",
      "  result = stats.anderson_ksamp([self.initial_stats[layer_name]['sample'], current_sample])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is there any correction:  1\n"
     ]
    }
   ],
   "source": [
    "model, correction = sdm.introduce_fault_with_sdm(model, FR, None, FP)\n",
    "# model = introduce_fault(model, FR, None, FP[0])\n",
    "print(\"Is there any correction: \", correction if correction else \"Nothing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594fc5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:  23%|█████████████████████████████████████████████████████▍                                                                                                                                                                                 | 2316/10000 [01:19<05:17, 24.19it/s]"
     ]
    }
   ],
   "source": [
    "top1_acc, top5_acc, early_output_counts, non_conf_output_counts, conf_violation_counts, unc_viol_with_fault = \\\n",
    "  sdm.sdn_test_early_exits_sdm(model, one_batch_dataset.test_loader, confidence_threshold, uncertainty_threshold, \"cpu\")\n",
    "\n",
    "print(\"top1_acc, top5_acc, early_output_counts, non_conf_output_counts, conf_violation_counts, unc_viol_with_fault: \",\n",
    "     top1_acc, top5_acc, early_output_counts, non_conf_output_counts, conf_violation_counts, unc_viol_with_fault)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeefa534",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
