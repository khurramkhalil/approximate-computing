{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98a115dd",
   "metadata": {},
   "source": [
    "# Model evaluation and re-training with AdaPT on Cifar10 dataset\n",
    "\n",
    "In this notebook you can evaluate different approximate multipliers on various models based on Cifar10 dataset\n",
    "\n",
    "Steps:\n",
    "* Select models to load \n",
    "* Select number of threads to use\n",
    "* Choose approximate multiplier \n",
    "* Load model for evaluation\n",
    "* Load dataset\n",
    "* Run model calibration for quantization\n",
    "* Run model evaluation\n",
    "* Run approximate-aware re-training\n",
    "* Rerun model evaluation\n",
    "\n",
    "**Note**:\n",
    "* This notebook should be run on a X86 machine\n",
    "\n",
    "* Please make sure you have run the installation steps first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5eef0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import requests\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms as T\n",
    "from torchvision.datasets import CIFAR10\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5d4c7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_seed():\n",
    "    return 1221 # 121 and 1221\n",
    "\n",
    "def set_random_seeds():\n",
    "    torch.manual_seed(get_random_seed())\n",
    "    np.random.seed(get_random_seed())\n",
    "    random.seed(get_random_seed())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab49b35",
   "metadata": {},
   "source": [
    "## Select models to load \n",
    "\n",
    "The weights must be downloaded in state_dicts folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "183a13aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.SDNs.vgg_sdn import vgg16_sdn_bn\n",
    "from models.SDNs.wideresnet_sdn import wideresnet_sdn_v1\n",
    "from models.SDNs.mobilenet_sdn import mobilenet_sdn_v1\n",
    "import models.SDNs.fault_injection as fie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69265983",
   "metadata": {},
   "source": [
    "## Select number of threads to use\n",
    "\n",
    "For optimal performance set them as the number of your cpu threads (not cpu cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "165c2d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: OMP_PLACES=cores\n",
      "env: OMP_PROC_BIND=close\n",
      "env: OMP_WAIT_POLICY=active\n"
     ]
    }
   ],
   "source": [
    "threads = 20\n",
    "torch.set_num_threads(threads)\n",
    "\n",
    "# maybe better performance\n",
    "%env OMP_PLACES=cores\n",
    "%env OMP_PROC_BIND=close\n",
    "%env OMP_WAIT_POLICY=active"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa06300",
   "metadata": {},
   "source": [
    "## Choose approximate multiplier \n",
    "\n",
    "Two approximate multipliers are already provided\n",
    "\n",
    "**mul8s_acc** - (header file: mul8s_acc.h)   <--  default\n",
    "\n",
    "**mul8s_1L2H** - (header file: mul8s_1L2H.h)\n",
    "\n",
    "\n",
    "\n",
    "In order to use your custom multiplier you need to use the provided tool (LUT_generator) to easily create the C++ header for your multiplier. Then you just place it inside the adapt/cpu-kernels/axx_mults folder. The name of the axx_mult here must match the name of the header file. The same axx_mult is used in all layers. \n",
    "\n",
    "Tip: If you want explicitly to set for each layer a different axx_mult you must do it from the model definition using the respective AdaPT_Conv2d class of each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "562689c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "axx_mult = 'mul8s_acc'\n",
    "# axx_mult = 'mul8s_1L2H'\n",
    "\n",
    "# axx_mult = 'mul8s_1L2L'\n",
    "\n",
    "# axx_mult = 'mul8s_1L2N'\n",
    "# axx_mult = 'mul8s_1L12'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b539e7e1",
   "metadata": {},
   "source": [
    "## Load model for evaluation\n",
    "\n",
    "Jit compilation method loads 'on the fly' the C++ extentions of the approximate multipliers. Then the pytorch model is loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc26796f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using /root/.cache/torch_extensions as PyTorch extensions root...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/kkfdh/adapt/adapt/adapt/cpu-kernels/axx_conv2d.cpp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# model = vgg16_sdn_bn(pretrained=True, axx_mult = axx_mult)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# model = wideresnet_sdn_v1(pretrained=True, axx_mult = axx_mult)\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmobilenet_sdn_v1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxx_mult\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43maxx_mult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m/workspace/adapt/examples/models/SDNs/mobilenet_sdn.py:224\u001b[0m, in \u001b[0;36mmobilenet_sdn_v1\u001b[0;34m(pretrained, path, progress, device, axx_mult, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m axx_mult_global\n\u001b[1;32m    222\u001b[0m axx_mult_global \u001b[38;5;241m=\u001b[39m axx_mult\n\u001b[0;32m--> 224\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wideresnet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmobilenet_sdn_v1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpretrained\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/adapt/examples/models/SDNs/mobilenet_sdn.py:203\u001b[0m, in \u001b[0;36m_wideresnet\u001b[0;34m(arch, pretrained, progress, device, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wideresnet\u001b[39m(arch, pretrained, progress, device, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 203\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mMobileNet_SDN\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pretrained:\n\u001b[1;32m    205\u001b[0m         script_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(\u001b[38;5;18m__file__\u001b[39m)\n",
      "File \u001b[0;32m/workspace/adapt/examples/models/SDNs/mobilenet_sdn.py:85\u001b[0m, in \u001b[0;36mMobileNet_SDN.__init__\u001b[0;34m(self, num_classes)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcur_output_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     84\u001b[0m init_conv \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 85\u001b[0m init_conv\u001b[38;5;241m.\u001b[39mappend(\u001b[43mapproxNN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdaPT_Conv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_channels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m)\n\u001b[1;32m     86\u001b[0m init_conv\u001b[38;5;241m.\u001b[39mappend(nn\u001b[38;5;241m.\u001b[39mBatchNorm2d(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_channels))\n\u001b[1;32m     87\u001b[0m init_conv\u001b[38;5;241m.\u001b[39mappend(nn\u001b[38;5;241m.\u001b[39mReLU(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n",
      "File \u001b[0;32m/workspace/adapt/adapt/approx_layers/axx_layers.py:209\u001b[0m, in \u001b[0;36mAdaPT_Conv2d.__init__\u001b[0;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias, padding_mode, axx_mult, device, dtype)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28msuper\u001b[39m(AdaPT_Conv2d, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    204\u001b[0m     in_channels, out_channels, kernel_size_, stride_, padding_, dilation_,\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01mFalse\u001b[39;00m, _pair(\u001b[38;5;241m0\u001b[39m), groups, bias, padding_mode, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfactory_kwargs)\n\u001b[1;32m    207\u001b[0m \u001b[38;5;66;03m#Jit compilation method for cpp extention\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;66;03m#set PyInit_ prefix to comply with the python module name\u001b[39;00m\n\u001b[0;32m--> 209\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxx_conv2d_kernel \u001b[38;5;241m=\u001b[39m \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPyInit_conv2d_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43maxx_mult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msources\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/kkfdh/adapt/adapt/adapt/cpu-kernels/axx_conv2d.cpp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_cflags\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m-DAXX_MULT=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43maxx_mult\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m -march=native -fopenmp -O3\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_ldflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m-lgomp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m groups \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m groups \u001b[38;5;241m!=\u001b[39m in_channels:\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAdaPT_Conv2d does not support groups != in_channels\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/cpp_extension.py:1079\u001b[0m, in \u001b[0;36mload\u001b[0;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_python_module, is_standalone, keep_intermediates)\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(name,\n\u001b[1;32m    989\u001b[0m          sources: Union[\u001b[38;5;28mstr\u001b[39m, List[\u001b[38;5;28mstr\u001b[39m]],\n\u001b[1;32m    990\u001b[0m          extra_cflags\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    998\u001b[0m          is_standalone\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    999\u001b[0m          keep_intermediates\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   1000\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m   1001\u001b[0m \u001b[38;5;124;03m    Loads a PyTorch C++ extension just-in-time (JIT).\u001b[39;00m\n\u001b[1;32m   1002\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1077\u001b[0m \u001b[38;5;124;03m                verbose=True)\u001b[39;00m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m-> 1079\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_jit_compile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1080\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1081\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43msources\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1082\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_cflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1083\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_cuda_cflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1084\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_ldflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1085\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_include_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1086\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbuild_directory\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_get_build_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1087\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1088\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwith_cuda\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1089\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_python_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1090\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_standalone\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1091\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_intermediates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_intermediates\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/cpp_extension.py:1262\u001b[0m, in \u001b[0;36m_jit_compile\u001b[0;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_python_module, is_standalone, keep_intermediates)\u001b[0m\n\u001b[1;32m   1260\u001b[0m with_cudnn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28many\u001b[39m([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcudnn\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m extra_ldflags \u001b[38;5;129;01mor\u001b[39;00m []])\n\u001b[1;32m   1261\u001b[0m old_version \u001b[38;5;241m=\u001b[39m JIT_EXTENSION_VERSIONER\u001b[38;5;241m.\u001b[39mget_version(name)\n\u001b[0;32m-> 1262\u001b[0m version \u001b[38;5;241m=\u001b[39m \u001b[43mJIT_EXTENSION_VERSIONER\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbump_version_if_changed\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1263\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1264\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1265\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbuild_arguments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mextra_cflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_cuda_cflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_ldflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_include_paths\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbuild_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuild_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwith_cuda\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_cuda\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_python_module\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_python_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_standalone\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_standalone\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1270\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1271\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m version \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1272\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m version \u001b[38;5;241m!=\u001b[39m old_version \u001b[38;5;129;01mand\u001b[39;00m verbose:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/_cpp_extension_versioner.py:45\u001b[0m, in \u001b[0;36mExtensionVersioner.bump_version_if_changed\u001b[0;34m(self, name, source_files, build_arguments, build_directory, with_cuda, is_python_module, is_standalone)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbump_version_if_changed\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     37\u001b[0m                             name,\n\u001b[1;32m     38\u001b[0m                             source_files,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     42\u001b[0m                             is_python_module,\n\u001b[1;32m     43\u001b[0m                             is_standalone):\n\u001b[1;32m     44\u001b[0m     hash_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 45\u001b[0m     hash_value \u001b[38;5;241m=\u001b[39m \u001b[43mhash_source_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhash_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource_files\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m     hash_value \u001b[38;5;241m=\u001b[39m hash_build_arguments(hash_value, build_arguments)\n\u001b[1;32m     47\u001b[0m     hash_value \u001b[38;5;241m=\u001b[39m update_hash(hash_value, build_directory)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/_cpp_extension_versioner.py:15\u001b[0m, in \u001b[0;36mhash_source_files\u001b[0;34m(hash_value, source_files)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhash_source_files\u001b[39m(hash_value, source_files):\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m source_files:\n\u001b[0;32m---> 15\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m     16\u001b[0m             hash_value \u001b[38;5;241m=\u001b[39m update_hash(hash_value, file\u001b[38;5;241m.\u001b[39mread())\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hash_value\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/kkfdh/adapt/adapt/adapt/cpu-kernels/axx_conv2d.cpp'"
     ]
    }
   ],
   "source": [
    "# model = vgg16_sdn_bn(pretrained=True, axx_mult = axx_mult)\n",
    "# model = wideresnet_sdn_v1(pretrained=True, axx_mult = axx_mult)\n",
    "model = mobilenet_sdn_v1(pretrained=True, axx_mult = axx_mult)\n",
    "\n",
    "model.eval() # for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de58a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds\n",
    "set_random_seeds()\n",
    "\n",
    "# Print names of immediate layers only\n",
    "for name, layer in model.named_modules():\n",
    "    print(name)\n",
    "    \n",
    "# layers.0.layers.0.quantizer\n",
    "# layers.0.layers.0.quantizer_w\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76721ed0",
   "metadata": {},
   "source": [
    "## Load dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f63b4701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "def val_dataloader(mean = (0.4914, 0.4822, 0.4465), std = (0.2471, 0.2435, 0.2616)):\n",
    "\n",
    "    transform = T.Compose(\n",
    "        [\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean, std),\n",
    "        ]\n",
    "    )\n",
    "    dataset = CIFAR10(root=\"datasets/cifar10_data\", train=False, download=True, transform=transform)\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=128,\n",
    "        num_workers=0,\n",
    "        drop_last=True,\n",
    "        pin_memory=False,\n",
    "    )\n",
    "    return dataloader\n",
    "\n",
    "transform = T.Compose(\n",
    "        [\n",
    "            T.RandomCrop(32, padding=4),\n",
    "            T.RandomHorizontalFlip(),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean = (0.485, 0.456, 0.406), std = (0.229, 0.224, 0.225)),\n",
    "        ]\n",
    "    )\n",
    "dataset = CIFAR10(root=\"datasets/cifar10_data\", train=True, download=True, transform=transform)\n",
    "\n",
    "evens = list(range(0, len(dataset), 10))\n",
    "trainset_1 = torch.utils.data.Subset(dataset, evens)\n",
    "\n",
    "data = val_dataloader()\n",
    "\n",
    "# data_t is used for calibration purposes and is a subset of train-set\n",
    "data_t = DataLoader(trainset_1, batch_size=128,\n",
    "                                            shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47aa7856",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddTrigger(object):\n",
    "    def __init__(self, square_size=5, square_loc=(26,26)):\n",
    "        self.square_size = square_size\n",
    "        self.square_loc = square_loc\n",
    "\n",
    "    def __call__(self, pil_data):\n",
    "        square = Image.new('L', (self.square_size, self.square_size), 255)\n",
    "        pil_data.paste(square, self.square_loc)\n",
    "        return pil_data\n",
    "\n",
    "class Cifar10_:\n",
    "    def __init__(self, batch_size=128, add_trigger=False):\n",
    "        self.batch_size = batch_size\n",
    "        self.img_size = 32\n",
    "        self.num_classes = 10\n",
    "        self.num_test = 10000\n",
    "        self.num_train = 50000\n",
    "\n",
    "        normalize = T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        self.augmented = T.Compose([T.RandomHorizontalFlip(), T.RandomCrop(32, padding=4),T.ToTensor(), normalize])\n",
    "\n",
    "        self.normalized = T.Compose([T.ToTensor(), normalize])\n",
    "\n",
    "        self.aug_trainset =  CIFAR10(root='datasets/cifar10_data', train=True, download=False, transform=self.augmented)\n",
    "        self.aug_train_loader = torch.utils.data.DataLoader(self.aug_trainset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "        self.trainset =  CIFAR10(root='datasets/cifar10_data', train=True, download=False, transform=self.normalized)\n",
    "        self.train_loader = torch.utils.data.DataLoader(self.trainset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        self.testset =  CIFAR10(root='datasets/cifar10_data', train=False, download=False, transform=self.normalized)\n",
    "        self.test_loader = torch.utils.data.DataLoader(self.testset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "        # add trigger to the test set samples\n",
    "        # for the experiments on the backdoored CNNs and SDNs\n",
    "        #  uncomment third line to measure backdoor attack success, right now it measures standard accuracy\n",
    "        if add_trigger: \n",
    "            self.trigger_transform = T.Compose([AddTrigger(), T.ToTensor(), normalize])\n",
    "            self.trigger_test_set = CIFAR10(root='datasets/cifar10_data', train=False, download=False, transform=self.trigger_transform)\n",
    "            # self.trigger_test_set.test_labels = [5] * self.num_test\n",
    "            self.trigger_test_loader = torch.utils.data.DataLoader(self.trigger_test_set, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "def load_cifar10(batch_size, add_trigger=False):\n",
    "    cifar10_data = Cifar10_(batch_size=batch_size, add_trigger=add_trigger)\n",
    "    return cifar10_data\n",
    "\n",
    "def get_dataset(batch_size=128, add_trigger=False):\n",
    "    return load_cifar10(batch_size, add_trigger)\n",
    "\n",
    "t_dataset = get_dataset()\n",
    "one_batch_dataset = get_dataset(1, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa74c5d",
   "metadata": {},
   "source": [
    "## Run model calibration for quantization\n",
    "\n",
    "Calibrates the quantization parameters \n",
    "\n",
    "Need to re-run it each time the model changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946f0d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_quantization import nn as quant_nn\n",
    "from pytorch_quantization import calib\n",
    "\n",
    "def collect_stats(model, data_loader, num_batches):\n",
    "     \"\"\"Feed data to the network and collect statistic\"\"\"\n",
    "\n",
    "     # Enable calibrators\n",
    "     for name, module in model.named_modules():\n",
    "         if isinstance(module, quant_nn.TensorQuantizer):\n",
    "             if module._calibrator is not None:\n",
    "                 module.disable_quant()\n",
    "                 module.enable_calib()\n",
    "             else:\n",
    "                 module.disable()\n",
    "\n",
    "     for i, (image, _) in tqdm(enumerate(data_loader), total=num_batches):\n",
    "         model(image.cpu())\n",
    "         if i >= num_batches:\n",
    "             break\n",
    "\n",
    "     # Disable calibrators\n",
    "     for name, module in model.named_modules():\n",
    "         if isinstance(module, quant_nn.TensorQuantizer):\n",
    "             if module._calibrator is not None:\n",
    "                 module.enable_quant()\n",
    "                 module.disable_calib()\n",
    "             else:\n",
    "                 module.enable()\n",
    "\n",
    "def compute_amax(model, **kwargs):\n",
    " # Load calib result\n",
    " for name, module in model.named_modules():\n",
    "     if isinstance(module, quant_nn.TensorQuantizer):\n",
    "         if module._calibrator is not None:\n",
    "             if isinstance(module._calibrator, calib.MaxCalibrator):\n",
    "                 module.load_calib_amax()\n",
    "             else:\n",
    "                 module.load_calib_amax(**kwargs)\n",
    "         print(F\"{name:40}: {module}\")\n",
    " model.cpu()\n",
    "\n",
    "# It is a bit slow since we collect histograms on CPU\n",
    "with torch.no_grad():\n",
    "    stats = collect_stats(model, data_t, num_batches=2)\n",
    "    amax = compute_amax(model, method=\"percentile\", percentile=99.99)\n",
    "    \n",
    "    # optional - test different calibration methods\n",
    "    #amax = compute_amax(model, method=\"mse\")\n",
    "    #amax = compute_amax(model, method=\"entropy\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cedaacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from models.SDNs.wideresnet_sdn import WideResNet_SDN\n",
    "\n",
    "# torch.save(model.state_dict(), 'wideresnet_state_dict_sdnn.pth')\n",
    "\n",
    "# models = WideResNet_SDN()\n",
    "# torch.load('wideresnet_state_dict_sdnn.pth', map_location=\"cpu\")\n",
    "# # models = models.load_state_dict(torch.load('wideresnet_state_dict_sdnn.pth', map_location=\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2570157d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import timeit\n",
    "# correct = 0\n",
    "# total = 0\n",
    "\n",
    "# model.eval()\n",
    "# start_time = timeit.default_timer()\n",
    "# with torch.no_grad():\n",
    "#     for iteraction, (images, labels) in tqdm(enumerate(data), total=len(data)):\n",
    "#         images, labels = images.to(\"cpu\"), labels.to(\"cpu\")\n",
    "#         outputs = model(images)[-1]\n",
    "#         _, predicted = torch.max(outputs.data, 1)\n",
    "#         total += labels.size(0)\n",
    "#         correct += (predicted == labels).sum().item()\n",
    "# print(timeit.default_timer() - start_time)\n",
    "# print('Accuracy of the network on the 10000 test images: %.4f %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851dddd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test the loaded model\n",
    "# # model.eval()\n",
    "# top1_test, top5_test, preds = fie.sdn_test_uncertainty(model, t_dataset.test_loader, \"cpu\")\n",
    "# print(\"Top-1 accuracy:\",top1_test)\n",
    "# print(\"Top-5 accuracy:\",top5_test)\n",
    "\n",
    "# # Sample prediction result\n",
    "# print(\"Correctly predicted?\",bool(preds[0][0]),\",Confidence:\",preds[0][1],\",Uncertainty:\",preds[0][2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9687d24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test early exit capability of the mend model with zero uncertainty threshold and confidence threshold of 0.8\n",
    "# # uncertainty_threshold = -10\n",
    "# # confidence_threshold = 0.6\n",
    "\n",
    "uncertainty_threshold = 8\n",
    "confidence_threshold = 0.5\n",
    "\n",
    "# fie.sdn_test_early_exits(model, one_batch_dataset.test_loader, confidence_threshold, uncertainty_threshold, \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecba4f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import mul8s_1L2L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2945e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "\n",
    "def introduce_fault(model, percent_of_faults, fault_loc = None, layer_to_attack = None):\n",
    "    model.eval()\n",
    "    for name, param in model.named_parameters():\n",
    "        if name in layer_to_attack: \n",
    "        \n",
    "            print(\"Attacked layer\",name)\n",
    "            print(param.shape)\n",
    "            w1 = param.data\n",
    "            wf1 = torch.flatten(w1)\n",
    "            no_of_faults = int(percent_of_faults * len(wf1)/100)\n",
    "            if (no_of_faults > len(wf1)):\n",
    "                no_of_faults = len(wf1)\n",
    "\n",
    "            print(\"Number of weights attacked\", no_of_faults)\n",
    "            if fault_loc is None:\n",
    "                fault_loc = random.sample(range(0, len(wf1)), no_of_faults)\n",
    "                fault = [random.uniform(-2, 2) for _ in range(len(fault_loc))]\n",
    "#                 print(\"fault location\", fault)\n",
    "            \n",
    "            for i in range(0, len(fault_loc)):\n",
    "#                 print(f\"Fault values, before {wf1[fault_loc[i]]},   after: {-wf1[fault_loc[i]]}\")\n",
    "#                 wf1[fault_loc[i]] = -wf1[fault_loc[i]]\n",
    "                wf1[fault_loc[i]] = torch.tensor(fault[i])\n",
    "            \n",
    "            wf11 = wf1.reshape(w1.shape)\n",
    "            param.data = wf11\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1317f7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FP = ['layers.0.layers.1.0.weight'] # Example layers in vgg16\n",
    "# FP = ['layers.0.layers.1.0.weight','layers.0.layers.0.2.weight']# Example layers in wideresnet\n",
    "FP = [\"init_conv.weight\"] # Example layers in wideresnet\n",
    "FR = 30\n",
    "\n",
    "model = introduce_fault(model, FR, None, FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46d653b",
   "metadata": {},
   "outputs": [],
   "source": [
    "top1_acc, top5_acc, early_output_counts, non_conf_output_counts, conf_violation_counts, unc_viol_with_fault = \\\n",
    "  fie.sdn_test_early_exits(model, one_batch_dataset.test_loader, confidence_threshold, uncertainty_threshold, \"cpu\")\n",
    "\n",
    "print(\"top1_acc, top5_acc, early_output_counts, non_conf_output_counts, conf_violation_counts, unc_viol_with_fault: \",\n",
    "     top1_acc, top5_acc, early_output_counts, non_conf_output_counts, conf_violation_counts, unc_viol_with_fault)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0d96ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pytorch_quantization import nn as quant_nn\n",
    "# from pytorch_quantization import calib\n",
    "\n",
    "# def collect_stats(model, data_loader, num_batches):\n",
    "#      \"\"\"Feed data to the network and collect statistic\"\"\"\n",
    "\n",
    "#      # Enable calibrators\n",
    "#      for name, module in model.named_modules():\n",
    "#          if isinstance(module, quant_nn.TensorQuantizer):\n",
    "#              if module._calibrator is not None:\n",
    "#                  module.disable_quant()\n",
    "#                  module.enable_calib()\n",
    "#              else:\n",
    "#                  module.disable()\n",
    "\n",
    "#      for i, (image, _) in tqdm(enumerate(data_loader), total=num_batches):\n",
    "#          model(image.cpu())\n",
    "#          if i >= num_batches:\n",
    "#              break\n",
    "\n",
    "#      # Disable calibrators\n",
    "#      for name, module in model.named_modules():\n",
    "#          if isinstance(module, quant_nn.TensorQuantizer):\n",
    "#              if module._calibrator is not None:\n",
    "#                  module.enable_quant()\n",
    "#                  module.disable_calib()\n",
    "#              else:\n",
    "#                  module.enable()\n",
    "\n",
    "# def compute_amax(model, **kwargs):\n",
    "#  # Load calib result\n",
    "#  for name, module in model.named_modules():\n",
    "#      if isinstance(module, quant_nn.TensorQuantizer):\n",
    "#          if module._calibrator is not None:\n",
    "#              if isinstance(module._calibrator, calib.MaxCalibrator):\n",
    "#                  module.load_calib_amax()\n",
    "#              else:\n",
    "#                  module.load_calib_amax(**kwargs)\n",
    "#          print(F\"{name:40}: {module}\")\n",
    "#  model.cpu()\n",
    "\n",
    "# # It is a bit slow since we collect histograms on CPU\n",
    "# with torch.no_grad():\n",
    "#     stats = collect_stats(model, data_t, num_batches=2)\n",
    "#     amax = compute_amax(model, method=\"percentile\", percentile=99.99)\n",
    "    \n",
    "#     # optional - test different calibration methods\n",
    "#     #amax = compute_amax(model, method=\"mse\")\n",
    "#     #amax = compute_amax(model, method=\"entropy\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594fc5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top1_acc, top5_acc, early_output_counts, non_conf_output_counts, conf_violation_counts, unc_viol_with_fault = \\\n",
    "#   fie.sdn_test_early_exits(model, one_batch_dataset.test_loader, confidence_threshold, uncertainty_threshold, \"cpu\")\n",
    "\n",
    "# print(\"top1_acc, top5_acc, early_output_counts, non_conf_output_counts, conf_violation_counts, unc_viol_with_fault: \",\n",
    "#      top1_acc, top5_acc, early_output_counts, non_conf_output_counts, conf_violation_counts, unc_viol_with_fault)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
